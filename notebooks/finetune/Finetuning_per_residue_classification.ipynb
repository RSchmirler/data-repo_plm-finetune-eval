{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876db82e",
   "metadata": {},
   "source": [
    "# Prot T5 Finetuning\n",
    "# per residue classification\n",
    "\n",
    "This notebook allows you to finetune PLMs to your own datasets\n",
    "\n",
    "For better perfomance we apply [Parameter-Efficient Fine-Tuning (PEFT)](https://huggingface.co/blog/peft). For this we apply [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685).\n",
    "\n",
    "For higher memory efficiency we also utilize the [deepspeed](https://github.com/microsoft/DeepSpeed) implementation of [huggingface](https://huggingface.co/docs/accelerate/usage_guides/deepspeed).\n",
    "\n",
    "The core training loop is implemented with the pytorch [huggingface trainer](https://huggingface.co/docs/transformers/main_classes/trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5ec35",
   "metadata": {},
   "source": [
    "## Imports and env. variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "angry-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os.path\n",
    "os.chdir(\"set working path here\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers.models.esm.modeling_esm import EsmPreTrainedModel, EsmModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# for custom DataCollator\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "import peft\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, inject_adapter_in_model, LoraConfig\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8534fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables to run Deepspeed from a notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9993\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bb08d",
   "metadata": {},
   "source": [
    "# Environment to run this notebook\n",
    "\n",
    "\n",
    "These are the versions of the core packages we use to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35bdadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  1.13.1\n",
      "Cuda version:  11.7\n",
      "Numpy version:  1.22.3\n",
      "Pandas version:  2.0.3\n",
      "Transformers version:  4.26.1\n",
      "Datasets version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109a4d7",
   "metadata": {},
   "source": [
    "**For easy setup of this environment you can use the finetuning.yml File provided in this folder**\n",
    "\n",
    "check here for [setting up env from a yml File](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c095834",
   "metadata": {},
   "source": [
    "# Valid Model checkpoints\n",
    "\n",
    "This notebook was tested with all models mentioned below.\n",
    "All required, model specific adaptations will be taken care of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4d7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESMs = [\"facebook/esm2_t6_8M_UR50D\",\n",
    "         \"facebook/esm2_t12_35M_UR50D\",\n",
    "         \"facebook/esm2_t30_150M_UR50D\",\n",
    "         \"facebook/esm2_t33_650M_UR50D\",\n",
    "         \"facebook/esm2_t36_3B_UR50D\"]\n",
    "\n",
    "T5s = [\"Rostlab/prot_t5_xl_uniref50\",\n",
    "       'Rostlab/ProstT5',\n",
    "       \"ElnaggarLab/ankh-base\",\n",
    "       \"ElnaggarLab/ankh-large\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6990465",
   "metadata": {},
   "source": [
    "### Select your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc43e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = T5s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2dda19",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "Provide your training and validation data in seperate pandas dataframes \n",
    "\n",
    "example shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c012178",
   "metadata": {},
   "source": [
    "**Modify the data loading part above as needed for your data**\n",
    "\n",
    "To run the training you need two dataframes (training and validation) each with the columns \"sequence\" and \"label\" and \"mask\"\n",
    "\n",
    "Columns are:\n",
    "+ protein sequence\n",
    "+ label is a list of len(protein sequence) with integers (from 0 to number of classes - 1) corresponding to predicted class at this position\n",
    "+ mask gives the possibility to ignore parts of the positions. Provide a list of len(protein sequence) where 1 is processed, while 0 is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea398922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1es5-A</td>\n",
       "      <td>VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a6h-E</td>\n",
       "      <td>MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b1a-P</td>\n",
       "      <td>MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ehi-C</td>\n",
       "      <td>GTGSQGETLGEKWKKKLNQLSRKEFDLYKKSGITEVDRTEAKEGLK...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5egf-A</td>\n",
       "      <td>HHHHHHAVAKDSTESKSWEPFSLSPIKDPQALHAALCSKNVIPVTS...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                           sequence  \\\n",
       "0  1es5-A  VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...   \n",
       "1  2a6h-E  MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...   \n",
       "2  5b1a-P  MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...   \n",
       "3  5ehi-C  GTGSQGETLGEKWKKKLNQLSRKEFDLYKKSGITEVDRTEAKEGLK...   \n",
       "4  5egf-A  HHHHHHAVAKDSTESKSWEPFSLSPIKDPQALHAALCSKNVIPVTS...   \n",
       "\n",
       "                                                mask  \\\n",
       "0  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                               label dataset  validation  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   train       False  \n",
       "1  [0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, ...   train       False  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   train       False  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, ...   train       False  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   train       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this example we import the secondary_structure dataset from https://github.com/J-SNACKKB/FLIP\n",
    "# For details, see publication here: https://openreview.net/forum?id=p2dMLEwL8tF\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from Bio import SeqIO\n",
    "import tempfile\n",
    "\n",
    "# Download the zip file from GitHub\n",
    "url = 'https://github.com/J-SNACKKB/FLIP/raw/main/splits/secondary_structure/splits.zip'\n",
    "\n",
    "response = requests.get(url)\n",
    "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
    "\n",
    "# Extract the fasta file to a temporary directory\n",
    "# Sequence File\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    zip_file.extract('splits/sequences.fasta', temp_dir)\n",
    "\n",
    "    # Load the fasta files\n",
    "    fasta_file = open(temp_dir + '/splits/sequences.fasta')\n",
    "    \n",
    "    # Load FASTA file using Biopython\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append([record.name, str(record.seq)])\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\"])\n",
    "\n",
    "# Mask File\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    zip_file.extract('splits/mask.fasta', temp_dir)\n",
    "\n",
    "    # Load the fasta files\n",
    "    fasta_file = open(temp_dir + '/splits/mask.fasta')\n",
    "    \n",
    "    # Load FASTA file using Biopython\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append([str(record.seq)])\n",
    "\n",
    "    # Add to dataframe\n",
    "    df = pd.concat([df, pd.DataFrame(sequences, columns=[\"mask\"])], axis=1) \n",
    "    \n",
    "# Label File\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    zip_file.extract('splits/sampled.fasta', temp_dir)\n",
    "\n",
    "    # Load the fasta files\n",
    "    fasta_file = open(temp_dir + '/splits/sampled.fasta')\n",
    "    \n",
    "    # Load FASTA file using Biopython\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "\n",
    "        sequences.append([str(record.seq), record.description])\n",
    "\n",
    "    # Add to dataframe\n",
    "    df = pd.concat([df, pd.DataFrame(sequences, columns=[ \"label\", \"dataset\"])], axis=1)  \n",
    "\n",
    "# Get data split information\n",
    "df[\"validation\"]=df.dataset.str.split(\"=\").str[2]\n",
    "# str to bool\n",
    "df['validation'] = df['validation'].apply(lambda x: x == 'True')\n",
    "\n",
    "# Extract data split information\n",
    "df[\"dataset\"]=df.dataset.str.split(\"=\").str[1]\n",
    "df[\"dataset\"]=df.dataset.str.split(\" \").str[0]\n",
    "\n",
    "# Preprocess mask and label to lists\n",
    "# C is class 0, E is class 1, H is class 2\n",
    "df['label'] = df['label'].str.replace(\"C\",\"0\")\n",
    "df['label'] = df['label'].str.replace(\"E\",\"1\")\n",
    "df['label'] = df['label'].str.replace(\"H\",\"2\")\n",
    "\n",
    "# str to integer\n",
    "df['label'] = df['label'].apply(lambda x: [int(i) for i in x])\n",
    "df['mask'] = df['mask'].apply(lambda x: [int(i) for i in x])\n",
    "\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a85fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate test and train data \n",
    "my_test=df[df.dataset==\"test\"].reset_index(drop=True)\n",
    "df=df[df.dataset==\"train\"]\n",
    "\n",
    "# Get train and validation data\n",
    "my_train=df[df.validation!=True].reset_index(drop=True)\n",
    "my_valid=df[df.validation==True].reset_index(drop=True)\n",
    "\n",
    "# Drop unneeded columns\n",
    "my_train= my_train[[\"sequence\",\"label\",\"mask\"]]\n",
    "my_valid= my_valid[[\"sequence\",\"label\",\"mask\"]]\n",
    "my_test =  my_test[[\"sequence\",\"label\",\"mask\"]]\n",
    "\n",
    "# Set labels where mask == 0 to -100 (will be ignored by pytorch loss)\n",
    "my_train['label'] = my_train.apply(lambda row: [-100 if m == 0 else l for l, m in zip(row['label'], row['mask'])], axis=1)\n",
    "my_valid['label'] = my_valid.apply(lambda row: [-100 if m == 0 else l for l, m in zip(row['label'], row['mask'])], axis=1)\n",
    "my_test['label'] = my_test.apply(lambda row: [-100 if m == 0 else l for l, m in zip(row['label'], row['mask'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f14d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...</td>\n",
       "      <td>[-100, -100, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...</td>\n",
       "      <td>[-100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GTGSQGETLGEKWKKKLNQLSRKEFDLYKKSGITEVDRTEAKEGLK...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, 0, 0, 2, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HHHHHHAVAKDSTESKSWEPFSLSPIKDPQALHAALCSKNVIPVTS...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  VTKPTIAAVGGYAMNNGTGTTLYTKAADTRRSTGSTTKIMTAKVVL...   \n",
       "1  MAEPGIDKLFGMVDSKYRLTVVVAKRAQQLLRHGFKNTVLEPEERP...   \n",
       "2  MTHQTHAYHMVNPSPWPLTGALSALLMTSGLTMWFHFNSMTLLMIG...   \n",
       "3  GTGSQGETLGEKWKKKLNQLSRKEFDLYKKSGITEVDRTEAKEGLK...   \n",
       "4  HHHHHHAVAKDSTESKSWEPFSLSPIKDPQALHAALCSKNVIPVTS...   \n",
       "\n",
       "                                               label  \\\n",
       "0  [-100, -100, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "1  [-100, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, ...   \n",
       "2  [-100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [-100, -100, -100, -100, -100, -100, 0, 0, 2, ...   \n",
       "4  [-100, -100, -100, -100, -100, -100, -100, -10...   \n",
       "\n",
       "                                                mask  \n",
       "0  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71fc6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GMKVTNYQGATIDPYSKGLGMVPGTSIQLTDAARLEWNLLNEDVSL...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMPLDAGGQNSTQMVLAPGASIFRCRQCGQTISRRDWLLPMGGDHE...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MHFEAYPPEVNSANIYAGPGPDSMLAAARAWRSLDVEMTAVQRSFN...</td>\n",
       "      <td>[-100, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNIPTTTTKGEQAKSQLIAAALAQFGEYGLHATTRDIAALAGQNIA...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, 0, 2, 2, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTSYENSLLVKQSGSLPLSSLTHVLRSLTPNARGIFRLLIKYQLDN...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  GMKVTNYQGATIDPYSKGLGMVPGTSIQLTDAARLEWNLLNEDVSL...   \n",
       "1  AMPLDAGGQNSTQMVLAPGASIFRCRQCGQTISRRDWLLPMGGDHE...   \n",
       "2  MHFEAYPPEVNSANIYAGPGPDSMLAAARAWRSLDVEMTAVQRSFN...   \n",
       "3  MNIPTTTTKGEQAKSQLIAAALAQFGEYGLHATTRDIAALAGQNIA...   \n",
       "4  GTSYENSLLVKQSGSLPLSSLTHVLRSLTPNARGIFRLLIKYQLDN...   \n",
       "\n",
       "                                               label  \\\n",
       "0  [-100, -100, -100, -100, -100, -100, -100, -10...   \n",
       "1  [-100, -100, -100, -100, -100, -100, -100, -10...   \n",
       "2  [-100, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "3  [-100, -100, -100, -100, -100, -100, 0, 2, 2, ...   \n",
       "4  [-100, -100, -100, -100, -100, -100, -100, -10...   \n",
       "\n",
       "                                                mask  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b996723",
   "metadata": {},
   "source": [
    "# Models and Low Rank Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104a610",
   "metadata": {},
   "source": [
    "## T5 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-channels",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Classification model definition \n",
    "\n",
    "adding a token classification head on top of the encoder model\n",
    "\n",
    "modified from [EsmForTokenClassification](https://github.com/huggingface/transformers/blob/v4.30.0/src/transformers/models/esm/modeling_esm.py#L1178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acting-archives",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.2, num_labels=3):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderForTokenClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1, self.num_labels)\n",
    "\n",
    "            active_labels = torch.where(\n",
    "              active_loss, labels.view(-1), torch.tensor(-100).type_as(labels)\n",
    "            )\n",
    "\n",
    "            valid_logits=active_logits[active_labels!=-100]\n",
    "            valid_labels=active_labels[active_labels!=-100]\n",
    "            \n",
    "            valid_labels=valid_labels.type(torch.LongTensor).to('cuda:0')\n",
    "            \n",
    "            loss = loss_fct(valid_logits, valid_labels)\n",
    "            \n",
    "        \n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0e217",
   "metadata": {},
   "source": [
    "### Load T5 model\n",
    "this creates a T5 model with prediction head and LoRA modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "split-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_T5_model_classification(checkpoint, num_labels, half_precision, full = False, deepspeed=True):\n",
    "    # Load model and tokenizer\n",
    "\n",
    "    if \"ankh\" in checkpoint :\n",
    "        model = T5EncoderModel.from_pretrained(checkpoint)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    elif \"prot_t5\" in checkpoint:\n",
    "        # possible to load the half precision model (thanks to @pawel-rezo for pointing that out)\n",
    "        if half_precision and deepspeed : \n",
    "            tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "            model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\", torch_dtype=torch.float16)#.to(torch.device('cuda')\n",
    "        else:\n",
    "            model = T5EncoderModel.from_pretrained(checkpoint)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "                \n",
    "    elif \"ProstT5\" in checkpoint:\n",
    "        if half_precision and deepspeed: \n",
    "            tokenizer = T5Tokenizer.from_pretrained(checkpoint, do_lower_case=False)\n",
    "            model = T5EncoderModel.from_pretrained(checkpoint, torch_dtype=torch.float16)#.to(torch.device('cuda')\n",
    "        else:\n",
    "            model = T5EncoderModel.from_pretrained(checkpoint)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(checkpoint) \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels)\n",
    "    class_model=T5EncoderForTokenClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    if full == True:\n",
    "        return model, tokenizer \n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"T5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # lora modification\n",
    "    peft_config = LoraConfig(\n",
    "        r=4, lora_alpha=1, bias=\"all\", target_modules=[\"q\",\"k\",\"v\",\"o\"]\n",
    "    )\n",
    "    \n",
    "    model = inject_adapter_in_model(peft_config, model)\n",
    "    \n",
    "    # Unfreeze the prediction head\n",
    "    for (param_name, param) in model.classifier.named_parameters():\n",
    "                param.requires_grad = True  \n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"T5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cc2cb8",
   "metadata": {},
   "source": [
    "## ESM2 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f92964",
   "metadata": {},
   "source": [
    "### Classification model definition and DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6173545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EsmForTokenClassificationCustom(EsmPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.esm = EsmModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.esm(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        # changed to ignore special tokens at the seq start and end \n",
    "        # as well as invalid positions (labels -100)\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1, self.num_labels)\n",
    "\n",
    "            active_labels = torch.where(\n",
    "              active_loss, labels.view(-1), torch.tensor(-100).type_as(labels)\n",
    "            )\n",
    "\n",
    "            valid_logits=active_logits[active_labels!=-100]\n",
    "            valid_labels=active_labels[active_labels!=-100]\n",
    "            \n",
    "            valid_labels=valid_labels.type(torch.LongTensor).to('cuda:0')\n",
    "            \n",
    "            loss = loss_fct(valid_logits, valid_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    \n",
    "# based on transformers DataCollatorForTokenClassification\n",
    "@dataclass\n",
    "class DataCollatorForTokenClassificationESM(DataCollatorMixin):\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "    Args:\n",
    "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
    "            The tokenizer used for encoding the data.\n",
    "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence is provided).\n",
    "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
    "              acceptable input length for the model if that argument is not provided.\n",
    "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
    "        max_length (`int`, *optional*):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (`int`, *optional*):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        label_pad_token_id (`int`, *optional*, defaults to -100):\n",
    "            The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions).\n",
    "        return_tensors (`str`):\n",
    "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def torch_call(self, features):\n",
    "        import torch\n",
    "\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature[label_name] for feature in features] if label_name in features[0].keys() else None\n",
    "\n",
    "        no_labels_features = [{k: v for k, v in feature.items() if k != label_name} for feature in features]\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            no_labels_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        if labels is None:\n",
    "            return batch\n",
    "\n",
    "        sequence_length = batch[\"input_ids\"].shape[1]\n",
    "        padding_side = self.tokenizer.padding_side\n",
    "\n",
    "        def to_list(tensor_or_iterable):\n",
    "            if isinstance(tensor_or_iterable, torch.Tensor):\n",
    "                return tensor_or_iterable.tolist()\n",
    "            return list(tensor_or_iterable)\n",
    "\n",
    "        if padding_side == \"right\":\n",
    "            batch[label_name] = [\n",
    "                # to_list(label) + [self.label_pad_token_id] * (sequence_length - len(label)) for label in labels\n",
    "                # changed to pad the special tokens at the beginning and end of the sequence\n",
    "                [self.label_pad_token_id] + to_list(label) + [self.label_pad_token_id] * (sequence_length - len(label)-1) for label in labels\n",
    "            ]\n",
    "        else:\n",
    "            batch[label_name] = [\n",
    "                [self.label_pad_token_id] * (sequence_length - len(label)) + to_list(label) for label in labels\n",
    "            ]\n",
    "\n",
    "        batch[label_name] = torch.tensor(batch[label_name], dtype=torch.float)\n",
    "        return batch\n",
    "\n",
    "def _torch_collate_batch(examples, tokenizer, pad_to_multiple_of: Optional[int] = None):\n",
    "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
    "    import torch\n",
    "\n",
    "    # Tensorize if necessary.\n",
    "    if isinstance(examples[0], (list, tuple, np.ndarray)):\n",
    "        examples = [torch.tensor(e, dtype=torch.long) for e in examples]\n",
    "\n",
    "    length_of_first = examples[0].size(0)\n",
    "\n",
    "    # Check if padding is necessary.\n",
    "\n",
    "    are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
    "    if are_tensors_same_length and (pad_to_multiple_of is None or length_of_first % pad_to_multiple_of == 0):\n",
    "        return torch.stack(examples, dim=0)\n",
    "\n",
    "    # If yes, check if we have a `pad_token`.\n",
    "    if tokenizer._pad_token is None:\n",
    "        raise ValueError(\n",
    "            \"You are attempting to pad samples but the tokenizer you are using\"\n",
    "            f\" ({tokenizer.__class__.__name__}) does not have a pad token.\"\n",
    "        )\n",
    "\n",
    "    # Creating the full tensor and filling it with our data.\n",
    "    max_length = max(x.size(0) for x in examples)\n",
    "    if pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
    "        max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
    "    result = examples[0].new_full([len(examples), max_length], tokenizer.pad_token_id)\n",
    "    for i, example in enumerate(examples):\n",
    "        if tokenizer.padding_side == \"right\":\n",
    "            result[i, : example.shape[0]] = example\n",
    "        else:\n",
    "            result[i, -example.shape[0] :] = example\n",
    "    return result\n",
    "\n",
    "def tolist(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif hasattr(x, \"numpy\"):  # Checks for TF tensors without needing the import\n",
    "        x = x.numpy()\n",
    "    return x.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b92e20",
   "metadata": {},
   "source": [
    "### Load ESM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61dd41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ESM2 models\n",
    "def load_esm_model_classification(checkpoint, num_labels, half_precision, full=False, deepspeed=True):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    \n",
    "    if half_precision and deepspeed:\n",
    "        model = EsmForTokenClassificationCustom.from_pretrained(checkpoint, num_labels = num_labels, torch_dtype = torch.float16)\n",
    "    else:\n",
    "        model = EsmForTokenClassificationCustom.from_pretrained(checkpoint, num_labels = num_labels)\n",
    "        \n",
    "    if full == True:\n",
    "        return model, tokenizer \n",
    "        \n",
    "    peft_config = LoraConfig(\n",
    "        r=4, lora_alpha=1, bias=\"all\", target_modules=[\"query\",\"key\",\"value\",\"dense\"]\n",
    "    )\n",
    "    \n",
    "    model = inject_adapter_in_model(peft_config, model)\n",
    "    \n",
    "    # Unfreeze the prediction head\n",
    "    for (param_name, param) in model.classifier.named_parameters():\n",
    "                param.requires_grad = True  \n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-yeast",
   "metadata": {},
   "source": [
    "# Training Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735e819",
   "metadata": {},
   "source": [
    "## Deepspeed config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eed91c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92962861",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "liberal-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels,checkpoint):\n",
    "    \n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    \n",
    "    if (\"esm\" in checkpoint) or (\"ProstT5\" in checkpoint):\n",
    "        # we need to cut of labels after 1022 positions for the data collator to add the correct padding (1022 + 2 special tokens)\n",
    "        labels = [l[:1022] for l in labels]       \n",
    "    else:\n",
    "        # we need to cut of labels after 1023 positions for the data collator to add the correct padding (1023 + 1 special tokens)\n",
    "        labels = [l[:1023] for l in labels] \n",
    "        \n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "     \n",
    "    return dataset\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_residue(\n",
    "        checkpoint,       #model checkpoint\n",
    "    \n",
    "        train_df,         #training data\n",
    "        valid_df,         #validation data      \n",
    "        num_labels = 3,   #number of classes\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch = 4,        #for training\n",
    "        accum = 2,        #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs = 10,      #training epochs\n",
    "        lr = 3e-4,        #recommended learning rate\n",
    "        seed = 42,        #random seed\n",
    "        deepspeed = False,#if gpu is large enough disable deepspeed for training speedup\n",
    "        mixed = True,     #enable mixed precision training\n",
    "        full = False,     #enable training of the full model (instead of LoRA)\n",
    "        gpu = 1 ):        #gpu selection (1 for first gpu)\n",
    "    \n",
    "    print(\"Model used:\", checkpoint, \"\\n\")\n",
    "    \n",
    "    # Correct incompatible training settings    \n",
    "    if \"ankh\" in checkpoint and mixed:\n",
    "        print(\"Ankh models do not support mixed precision training!\")\n",
    "        print(\"switched to FULL PRECISION TRAINING instead\")\n",
    "        mixed = False\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    if \"esm\" in checkpoint:\n",
    "        model, tokenizer = load_esm_model_classification(checkpoint, num_labels, mixed, full, deepspeed)\n",
    "    else:\n",
    "        model, tokenizer = load_T5_model_classification(checkpoint, num_labels, mixed, full, deepspeed)\n",
    "\n",
    "    # Preprocess inputs\n",
    "    # Replace uncommon AAs with \"X\"\n",
    "    train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "    valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "    \n",
    "    # Add spaces between each amino acid for ProtT5 and ProstT5 to correctly use them\n",
    "    if \"Rostlab\" in checkpoint:\n",
    "        train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "        valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "        \n",
    "    # Add <AA2fold> for ProstT5 to inform the model of the input type (amino acid sequence here)\n",
    "    if \"ProstT5\" in checkpoint:    \n",
    "        train_df['sequence']=train_df.apply(lambda row : \"<AA2fold> \" + row[\"sequence\"], axis = 1)  \n",
    "        valid_df['sequence']=valid_df.apply(lambda row : \"<AA2fold> \" + row[\"sequence\"], axis = 1)\n",
    "\n",
    "    # Create Datasets\n",
    "    train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']),checkpoint)\n",
    "    valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']),checkpoint)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    args = TrainingArguments(\n",
    "        \"./scripts/Finetuning/PT5/\",\n",
    "        evaluation_strategy = \"steps\", #we set this to \"steps\" because we train only for a single epoch here\n",
    "        eval_steps = 500,              #but still want to get intermediate evaluation results\n",
    "        logging_strategy = \"epoch\",\n",
    "        save_strategy = \"no\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch,\n",
    "        #per_device_eval_batch_size=val_batch,\n",
    "        per_device_eval_batch_size=batch,\n",
    "        gradient_accumulation_steps=accum,\n",
    "        num_train_epochs=epochs,\n",
    "        seed = seed,\n",
    "        deepspeed= ds_config if deepspeed else None,\n",
    "        fp16 = mixed,\n",
    "    ) \n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "\n",
    "        metric = load(\"accuracy\")\n",
    "        predictions, labels = eval_pred\n",
    "        \n",
    "        labels = labels.reshape((-1,))\n",
    "        \n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "        predictions = predictions.reshape((-1,))\n",
    "        \n",
    "        predictions = predictions[labels!=-100]\n",
    "        labels = labels[labels!=-100]\n",
    "        \n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # For token classification we need a data collator here to pad correctly\n",
    "    # For esm2 and Prost pad at the beginning and at the end\n",
    "    if (\"esm\" in checkpoint) or (\"ProstT5\" in checkpoint):\n",
    "        data_collator = DataCollatorForTokenClassificationESM(tokenizer) \n",
    "    # For Ankh and ProtT5 pad only at the end\n",
    "    else:\n",
    "        data_collator = DataCollatorForTokenClassification(tokenizer)        \n",
    "\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=valid_set,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )    \n",
    "    \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac94ab1",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede09d5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83fd6b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: Rostlab/prot_t5_xl_uniref50 \n",
      "\n",
      "T5_Classfier\n",
      "Trainable Parameter: 1208144899\n",
      "T5_LoRA_Classfier\n",
      "Trainable Parameter: 1970179\n",
      "\n",
      "[2024-04-23 11:58:13,861] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 11:58:14,083] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed info: version=0.8.1, git-hash=unknown, git-branch=unknown\n",
      "[2024-04-23 11:58:15,511] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-04-23 11:58:16,766] [WARNING] [cpu_adam.py:83:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /homes/schmirx6/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /homes/schmirx6/.cache/torch_extensions/py39_cu117/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 3.152190685272217 seconds\n",
      "[2024-04-23 11:58:21,680] [INFO] [logging.py:75:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2024-04-23 11:58:21,694] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2024-04-23 11:58:21,695] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2024-04-23 11:58:21,695] [INFO] [logging.py:75:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2024-04-23 11:58:21,696] [INFO] [stage_1_and_2.py:144:__init__] Reduce bucket size 200000000\n",
      "[2024-04-23 11:58:21,696] [INFO] [stage_1_and_2.py:145:__init__] Allgather bucket size 200000000\n",
      "[2024-04-23 11:58:21,697] [INFO] [stage_1_and_2.py:146:__init__] CPU Offload: True\n",
      "[2024-04-23 11:58:21,697] [INFO] [stage_1_and_2.py:147:__init__] Round robin gradient partitioning: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /homes/schmirx6/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "Emitting ninja build file /homes/schmirx6/.cache/torch_extensions/py39_cu117/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load utils op: 0.5012030601501465 seconds\n",
      "Rank: 0 partition count [1] and sizes[(1970180, False)] \n",
      "[2024-04-23 11:58:22,498] [INFO] [utils.py:825:see_memory_usage] Before initializing optimizer states\n",
      "[2024-04-23 11:58:22,499] [INFO] [utils.py:826:see_memory_usage] MA 2.25 GB         Max_MA 2.25 GB         CA 2.44 GB         Max_CA 2 GB \n",
      "[2024-04-23 11:58:22,500] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 43.77 GB, percent = 23.4%\n",
      "[2024-04-23 11:58:22,733] [INFO] [utils.py:825:see_memory_usage] After initializing optimizer states\n",
      "[2024-04-23 11:58:22,734] [INFO] [utils.py:826:see_memory_usage] MA 2.25 GB         Max_MA 2.25 GB         CA 2.44 GB         Max_CA 2 GB \n",
      "[2024-04-23 11:58:22,735] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 43.77 GB, percent = 23.4%\n",
      "[2024-04-23 11:58:22,735] [INFO] [stage_1_and_2.py:527:__init__] optimizer state initialized\n",
      "[2024-04-23 11:58:22,936] [INFO] [utils.py:825:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-04-23 11:58:22,937] [INFO] [utils.py:826:see_memory_usage] MA 2.25 GB         Max_MA 2.25 GB         CA 2.44 GB         Max_CA 2 GB \n",
      "[2024-04-23 11:58:22,938] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 43.77 GB, percent = 23.4%\n",
      "[2024-04-23 11:58:22,944] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2024-04-23 11:58:22,945] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2024-04-23 11:58:22,945] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f05d8d132e0>\n",
      "[2024-04-23 11:58:22,946] [INFO] [logging.py:75:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 11:58:22,949] [INFO] [config.py:1009:print] DeepSpeedEngine configuration:\n",
      "[2024-04-23 11:58:22,950] [INFO] [config.py:1013:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-04-23 11:58:22,951] [INFO] [config.py:1013:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-04-23 11:58:22,951] [INFO] [config.py:1013:print]   amp_enabled .................. False\n",
      "[2024-04-23 11:58:22,952] [INFO] [config.py:1013:print]   amp_params ................... False\n",
      "[2024-04-23 11:58:22,953] [INFO] [config.py:1013:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-04-23 11:58:22,954] [INFO] [config.py:1013:print]   bfloat16_enabled ............. False\n",
      "[2024-04-23 11:58:22,955] [INFO] [config.py:1013:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-04-23 11:58:22,956] [INFO] [config.py:1013:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-04-23 11:58:22,956] [INFO] [config.py:1013:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-04-23 11:58:22,957] [INFO] [config.py:1013:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f05d8d07d60>\n",
      "[2024-04-23 11:58:22,958] [INFO] [config.py:1013:print]   communication_data_type ...... None\n",
      "[2024-04-23 11:58:22,959] [INFO] [config.py:1013:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-04-23 11:58:22,959] [INFO] [config.py:1013:print]   curriculum_enabled_legacy .... False\n",
      "[2024-04-23 11:58:22,960] [INFO] [config.py:1013:print]   curriculum_params_legacy ..... False\n",
      "[2024-04-23 11:58:22,961] [INFO] [config.py:1013:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-04-23 11:58:22,962] [INFO] [config.py:1013:print]   data_efficiency_enabled ...... False\n",
      "[2024-04-23 11:58:22,962] [INFO] [config.py:1013:print]   dataloader_drop_last ......... False\n",
      "[2024-04-23 11:58:22,963] [INFO] [config.py:1013:print]   disable_allgather ............ False\n",
      "[2024-04-23 11:58:22,964] [INFO] [config.py:1013:print]   dump_state ................... False\n",
      "[2024-04-23 11:58:22,964] [INFO] [config.py:1013:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2024-04-23 11:58:22,965] [INFO] [config.py:1013:print]   eigenvalue_enabled ........... False\n",
      "[2024-04-23 11:58:22,966] [INFO] [config.py:1013:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-04-23 11:58:22,967] [INFO] [config.py:1013:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-04-23 11:58:22,967] [INFO] [config.py:1013:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-04-23 11:58:22,968] [INFO] [config.py:1013:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-04-23 11:58:22,969] [INFO] [config.py:1013:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-04-23 11:58:22,970] [INFO] [config.py:1013:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-04-23 11:58:22,970] [INFO] [config.py:1013:print]   eigenvalue_verbose ........... False\n",
      "[2024-04-23 11:58:22,971] [INFO] [config.py:1013:print]   elasticity_enabled ........... False\n",
      "[2024-04-23 11:58:22,972] [INFO] [config.py:1013:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-04-23 11:58:22,973] [INFO] [config.py:1013:print]   fp16_auto_cast ............... False\n",
      "[2024-04-23 11:58:22,973] [INFO] [config.py:1013:print]   fp16_enabled ................. True\n",
      "[2024-04-23 11:58:22,974] [INFO] [config.py:1013:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-04-23 11:58:22,975] [INFO] [config.py:1013:print]   global_rank .................. 0\n",
      "[2024-04-23 11:58:22,975] [INFO] [config.py:1013:print]   grad_accum_dtype ............. None\n",
      "[2024-04-23 11:58:22,976] [INFO] [config.py:1013:print]   gradient_accumulation_steps .. 1\n",
      "[2024-04-23 11:58:22,977] [INFO] [config.py:1013:print]   gradient_clipping ............ 1.0\n",
      "[2024-04-23 11:58:22,978] [INFO] [config.py:1013:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-04-23 11:58:22,978] [INFO] [config.py:1013:print]   initial_dynamic_scale ........ 65536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 11:58:22,979] [INFO] [config.py:1013:print]   load_universal_checkpoint .... False\n",
      "[2024-04-23 11:58:22,980] [INFO] [config.py:1013:print]   loss_scale ................... 0\n",
      "[2024-04-23 11:58:22,981] [INFO] [config.py:1013:print]   memory_breakdown ............. False\n",
      "[2024-04-23 11:58:22,981] [INFO] [config.py:1013:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-04-23 11:58:22,982] [INFO] [config.py:1013:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-04-23 11:58:22,983] [INFO] [config.py:1013:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-04-23 11:58:22,983] [INFO] [config.py:1013:print]   optimizer_name ............... adamw\n",
      "[2024-04-23 11:58:22,984] [INFO] [config.py:1013:print]   optimizer_params ............. {'lr': 0.0003, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2024-04-23 11:58:22,985] [INFO] [config.py:1013:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2024-04-23 11:58:22,986] [INFO] [config.py:1013:print]   pld_enabled .................. False\n",
      "[2024-04-23 11:58:22,986] [INFO] [config.py:1013:print]   pld_params ................... False\n",
      "[2024-04-23 11:58:22,987] [INFO] [config.py:1013:print]   prescale_gradients ........... False\n",
      "[2024-04-23 11:58:22,988] [INFO] [config.py:1013:print]   scheduler_name ............... WarmupLR\n",
      "[2024-04-23 11:58:22,989] [INFO] [config.py:1013:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.0003, 'warmup_num_steps': 0}\n",
      "[2024-04-23 11:58:22,989] [INFO] [config.py:1013:print]   sparse_attention ............. None\n",
      "[2024-04-23 11:58:22,990] [INFO] [config.py:1013:print]   sparse_gradients_enabled ..... False\n",
      "[2024-04-23 11:58:22,991] [INFO] [config.py:1013:print]   steps_per_print .............. 2000\n",
      "[2024-04-23 11:58:22,992] [INFO] [config.py:1013:print]   train_batch_size ............. 1\n",
      "[2024-04-23 11:58:22,992] [INFO] [config.py:1013:print]   train_micro_batch_size_per_gpu  1\n",
      "[2024-04-23 11:58:22,993] [INFO] [config.py:1013:print]   use_node_local_storage ....... False\n",
      "[2024-04-23 11:58:22,994] [INFO] [config.py:1013:print]   wall_clock_breakdown ......... False\n",
      "[2024-04-23 11:58:22,994] [INFO] [config.py:1013:print]   world_size ................... 1\n",
      "[2024-04-23 11:58:22,995] [INFO] [config.py:1013:print]   zero_allow_untested_optimizer  False\n",
      "[2024-04-23 11:58:22,996] [INFO] [config.py:1013:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
      "[2024-04-23 11:58:22,997] [INFO] [config.py:1013:print]   zero_enabled ................. True\n",
      "[2024-04-23 11:58:22,997] [INFO] [config.py:1013:print]   zero_optimization_stage ...... 2\n",
      "[2024-04-23 11:58:22,998] [INFO] [config.py:998:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.0003, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.0003, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /homes/schmirx6/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "***** Running training *****\n",
      "  Num examples = 9712\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9712\n",
      "  Number of trainable parameters = 1970179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load utils op: 0.00036144256591796875 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000300, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2024-04-23 11:58:23,464] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9712' max='9712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9712/9712 2:12:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.845744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.363770</td>\n",
       "      <td>0.852233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.855216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354736</td>\n",
       "      <td>0.855110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.348145</td>\n",
       "      <td>0.858154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.342041</td>\n",
       "      <td>0.860153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341309</td>\n",
       "      <td>0.859748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341553</td>\n",
       "      <td>0.860824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335693</td>\n",
       "      <td>0.862174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.334229</td>\n",
       "      <td>0.863330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331055</td>\n",
       "      <td>0.863811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331299</td>\n",
       "      <td>0.863910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.865493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331543</td>\n",
       "      <td>0.863925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.326660</td>\n",
       "      <td>0.865577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330566</td>\n",
       "      <td>0.864318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>0.866561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322998</td>\n",
       "      <td>0.866527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.321289</td>\n",
       "      <td>0.867473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 11:58:23,883] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:12:33,162] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 12:12:33,580] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
      "[2024-04-23 12:13:20,177] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:23:07,839] [INFO] [logging.py:75:log_dist] [Rank 0] step=2000, skipped=5, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:23:07,841] [INFO] [timer.py:198:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=2.3304379357583596, CurrSamplesPerSec=2.4008389161862285, MemAllocated=2.25GB, MaxMemAllocated=10.9GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:41:14,031] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 12:41:14,441] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:50:49,325] [INFO] [logging.py:75:log_dist] [Rank 0] step=4000, skipped=7, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:50:49,326] [INFO] [timer.py:198:stop] epoch=0/micro_step=4000/global_step=4000, RunningAvgSamplesPerSec=2.3578940476491885, CurrSamplesPerSec=2.41496223800221, MemAllocated=2.25GB, MaxMemAllocated=10.9GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:54:56,301] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 12:54:56,712] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 13:08:35,375] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 13:08:35,788] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 13:18:05,649] [INFO] [logging.py:75:log_dist] [Rank 0] step=6000, skipped=11, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 13:18:05,650] [INFO] [timer.py:198:stop] epoch=0/micro_step=6000/global_step=6000, RunningAvgSamplesPerSec=2.3845261086647764, CurrSamplesPerSec=2.4540019155507733, MemAllocated=2.25GB, MaxMemAllocated=10.9GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 13:22:14,336] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 13:22:14,751] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 13:35:59,036] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 13:35:59,450] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
      "[2024-04-23 13:37:35,813] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 13:45:29,736] [INFO] [logging.py:75:log_dist] [Rank 0] step=8000, skipped=16, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 13:45:29,737] [INFO] [timer.py:198:stop] epoch=0/micro_step=8000/global_step=8000, RunningAvgSamplesPerSec=2.39376710024645, CurrSamplesPerSec=2.457510243278224, MemAllocated=2.25GB, MaxMemAllocated=10.9GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 14:04:52,725] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 65536.0\n",
      "[2024-04-23 14:04:53,135] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1080\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_residue(checkpoint, my_train, my_valid, num_labels=3, batch=1, accum=1, epochs=1, seed=42, gpu=2, mixed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bab485",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8465267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Get accuracy value \n",
    "metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs_loss = [x['epoch'] for x in history if 'loss' in x]\n",
    "epochs_eval = [x['epoch'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "# For the loss we plot a horizontal line because we have just one loss value (after the first epoch)\n",
    "# Exchange the two lines below if you trained multiple epochs\n",
    "line1 = ax1.plot([0]+epochs_loss, loss*2, label='train_loss')\n",
    "#line1 = ax1.plot(epochs_loss, loss, label='train_loss')\n",
    "\n",
    "line2 = ax1.plot(epochs_eval, val_loss, label='val_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "line3 = ax2.plot(epochs_eval, metric, color='red', label='val_accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 + line3\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4a53e",
   "metadata": {},
   "source": [
    "# Save and Load the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ade4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(checkpoint, filepath, num_labels=3, mixed = True, full = False, deepspeed=True):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load model\n",
    "    if \"esm\" in checkpoint:\n",
    "        model, tokenizer = load_esm_model_classification(checkpoint, num_labels, mixed, full, deepspeed)\n",
    "    else:\n",
    "        model, tokenizer = load_T5_model_classification(checkpoint, num_labels, mixed, full, deepspeed)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ba621",
   "metadata": {},
   "source": [
    "This saves only the finetuned weights to a .pth file\n",
    "\n",
    "The file has a size of only a few MB, while the entire model would be around 4.8 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d31dc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,\"./ProtT5_secstr_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e96aa",
   "metadata": {},
   "source": [
    "To load the weights again, we initialize a new PT5 model from the pretrained checkpoint and load the LoRA weights afterwards\n",
    "\n",
    "You need to specifiy the correct num_labels here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edbd69f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/spiece.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Rostlab/prot_t5_xl_half_uniref50-enc\",\n",
      "  \"architectures\": [\n",
      "    \"T5EncoderModel\"\n",
      "  ],\n",
      "  \"d_ff\": 16384,\n",
      "  \"d_kv\": 128,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Rostlab/prot_t5_xl_half_uniref50-enc\",\n",
      "  \"architectures\": [\n",
      "    \"T5EncoderModel\"\n",
      "  ],\n",
      "  \"d_ff\": 16384,\n",
      "  \"d_kv\": 128,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/pytorch_model.bin\n",
      "Instantiating T5EncoderModel model under default dtype torch.float16.\n",
      "All model checkpoint weights were used when initializing T5EncoderModel.\n",
      "\n",
      "All the weights of T5EncoderModel were initialized from the model checkpoint at Rostlab/prot_t5_xl_half_uniref50-enc.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5EncoderModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5_Classfier\n",
      "Trainable Parameter: 1208144899\n",
      "T5_LoRA_Classfier\n",
      "Trainable Parameter: 1970179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model_reload = load_model(checkpoint, \"./ProtT5_secstr_finetuned.pth\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5289780",
   "metadata": {},
   "source": [
    "To check if the original and the reloaded models are identical we can compare weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e152714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c478158",
   "metadata": {},
   "source": [
    "# Make predictions on a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08533e20",
   "metadata": {},
   "source": [
    "This time we take the test data we prepared before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1151f4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M T P A V T T Y K L V I N G K T L K G E T T T ...</td>\n",
       "      <td>[-100, -100, -100, -100, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M N D Q E K I D K F T H S Y I N D D F G L T I ...</td>\n",
       "      <td>[-100, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G P G F M R D S G S K A S S D S Q D A N Q C C ...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S N A L S R N E V L L N G D I N F K E V R C V ...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M A K G K S E V V E Q N H T L I L G W S D K L ...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  M T P A V T T Y K L V I N G K T L K G E T T T ...   \n",
       "1  M N D Q E K I D K F T H S Y I N D D F G L T I ...   \n",
       "2  G P G F M R D S G S K A S S D S Q D A N Q C C ...   \n",
       "3  S N A L S R N E V L L N G D I N F K E V R C V ...   \n",
       "4  M A K G K S E V V E Q N H T L I L G W S D K L ...   \n",
       "\n",
       "                                               label  \n",
       "0  [-100, -100, -100, -100, 0, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [-100, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, ...  \n",
       "2  [-100, -100, -100, -100, -100, -100, -100, -10...  \n",
       "3  [-100, -100, -100, -100, -100, -100, -100, 0, ...  \n",
       "4  [-100, -100, -100, -100, -100, -100, -100, -10...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unneeded columns (remember, mask was already included as -100 values to label)\n",
    "my_test=my_test[[\"sequence\",\"label\"]]\n",
    "\n",
    "# Preprocess sequences\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "my_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249f897",
   "metadata": {},
   "source": [
    "Then we create predictions on our test data using the model we trained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1df2299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [01:39<00:00,  4.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']),checkpoint)\n",
    "# Make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# For token classification we need a data collator here to pad correctly\n",
    "if (\"esm\" in checkpoint) or (\"ProstT5\" in checkpoint):\n",
    "    data_collator = DataCollatorForTokenClassificationESM(tokenizer) \n",
    "# For Ankh and ProtT5 pad only at the end\n",
    "else:\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)  \n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle = False, collate_fn = data_collator)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = []\n",
    "# We need to collect the batch[\"labels\"] as well, this allows us to filter out all positions with a -100 afterwards\n",
    "padded_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # Padded labels from the data collator\n",
    "        padded_labels += batch['labels'].tolist()\n",
    "        # Add batch results(logits) to predictions, we take the argmax here to get the predicted class\n",
    "        predictions += model.float()(input_ids, attention_mask=attention_mask).logits.argmax(dim=-1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18401de",
   "metadata": {},
   "source": [
    "Finally, we compute our desired performance metric for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "000028da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8461466579449732\n"
     ]
    }
   ],
   "source": [
    "# to make it easier we flatten both the label and prediction lists\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "# flatten and convert to np array for easy slicing in the next step\n",
    "predictions = np.array(flatten(predictions))\n",
    "padded_labels = np.array(flatten(padded_labels))\n",
    "\n",
    "# Filter out all invalid (label = -100) values\n",
    "predictions = predictions[padded_labels!=-100]\n",
    "padded_labels = padded_labels[padded_labels!=-100]\n",
    "\n",
    "# Calculate classification Accuracy\n",
    "print(\"Accuracy: \", accuracy_score(padded_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee716709",
   "metadata": {},
   "source": [
    "Great, 84.6% Accuracy is a decent test performance for the \"new_pisces\" dataset (see results in [Table 7](https://ieeexplore.ieee.org/ielx7/34/9893033/9477085/supp1-3095381.pdf?arnumber=9477085) \"NEW364\" )\n",
    "\n",
    "Further hyperparameter optimization will most likely increase performance"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb",
     "timestamp": 1670229986129
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "023504ef79df47cd9f5672b3537d781e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3f0b29c16df48f798dbdabc99207f2c",
       "IPY_MODEL_fb9ce840b4644d6eab03736688e57e23",
       "IPY_MODEL_dcb559ab088446f0a4cc9ae4720f8c29"
      ],
      "layout": "IPY_MODEL_cf11d66697d84676b9d8af11a2edd064"
     }
    },
    "07e6f8ff49d74ced96b87afaf99f52c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a7bab101d504c7cbe0c0e21222e4010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e739bd554404481b4cfac9cd1710224",
      "max": 95,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b66c522257d04820932c9c7014392136",
      "value": 95
     }
    },
    "0c9bd61e2e904fdaa4f578c19c0f6ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14ba9ccca4004a1e944767648e2b1253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d04e61e6abfe42b9afab583bcab66b92",
      "placeholder": "​",
      "style": "IPY_MODEL_279e487c47954c9abc0a57daab09f66a",
      "value": "Downloading: 100%"
     }
    },
    "14eaa8780fd543b38d5ea5da8e002b1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a28a789e7814ee283b8ba922ecce252",
      "placeholder": "​",
      "style": "IPY_MODEL_3149e4afc57146ceac1fdd9a1902ccbc",
      "value": "Downloading: 100%"
     }
    },
    "15e24c603abb456984509d77813a0cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ef0944bc4334b32a1a5e136b3fce9e6",
      "placeholder": "​",
      "style": "IPY_MODEL_c6407f5a50b34a0d9bfbd916ffb70d17",
      "value": " 134M/134M [00:01&lt;00:00, 79.0MB/s]"
     }
    },
    "1bdf17da40fb4d8687456e5379af5da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f5719ff48504d91968e1953107b060f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "279e487c47954c9abc0a57daab09f66a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f1f8e5d1f5343978ccf1cc5dff59718": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305e2c8af6194f4486b505ff25be86d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_611417b8118744c28ec2619c45b2a6ec",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd89abbac71740c5a013481dd9129f5b",
      "value": 125
     }
    },
    "3149e4afc57146ceac1fdd9a1902ccbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "334e77a8b6284dfb886fefadea6998ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37dce533ad7648d0a09b3ef825c5aa31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d579e0c846b4e1bbc360d0ff2f2eccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4db0117d9ac0453886964613627decc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51b29673275343998567b43347eb591b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52a93c8ac4454ed1bf1a0d4711074bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d154e8e8a650447ab06425706d908f4e",
       "IPY_MODEL_0a7bab101d504c7cbe0c0e21222e4010",
       "IPY_MODEL_c8b35d958ecc4f3683b86278b979f300"
      ],
      "layout": "IPY_MODEL_4db0117d9ac0453886964613627decc0"
     }
    },
    "611417b8118744c28ec2619c45b2a6ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ae302430d7746edbc04b6786bdc53f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14ba9ccca4004a1e944767648e2b1253",
       "IPY_MODEL_e499b443a3964dc2bca05692abde2dda",
       "IPY_MODEL_15e24c603abb456984509d77813a0cf7"
      ],
      "layout": "IPY_MODEL_1f5719ff48504d91968e1953107b060f"
     }
    },
    "6c3f28dcd36d434fa8e5fe38b1d34e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d4673cb688f4dacb1e96a0d80815667",
       "IPY_MODEL_305e2c8af6194f4486b505ff25be86d7",
       "IPY_MODEL_a6f664af44464825a9c8b73215b59318"
      ],
      "layout": "IPY_MODEL_2f1f8e5d1f5343978ccf1cc5dff59718"
     }
    },
    "6e739bd554404481b4cfac9cd1710224": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "728fbf87d2ff4bed925f67c9cf0e36b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a00dda470ef4f0893676c794e006a8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8921dca0901741c5ab7723ca88803543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14eaa8780fd543b38d5ea5da8e002b1e",
       "IPY_MODEL_abee545f24074d33a2a171f140d84ca4",
       "IPY_MODEL_d2d78bbb74664973b1cde561152e9aad"
      ],
      "layout": "IPY_MODEL_fefc4de84c7847bf88635bfcad3a5f9e"
     }
    },
    "8d4673cb688f4dacb1e96a0d80815667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_728fbf87d2ff4bed925f67c9cf0e36b7",
      "placeholder": "​",
      "style": "IPY_MODEL_97335231c9ab4668bc8cdaee57be202f",
      "value": "Downloading: 100%"
     }
    },
    "97335231c9ab4668bc8cdaee57be202f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a28a789e7814ee283b8ba922ecce252": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ef0944bc4334b32a1a5e136b3fce9e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6f664af44464825a9c8b73215b59318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc1cf1de39dc45d69551ca2ca401a447",
      "placeholder": "​",
      "style": "IPY_MODEL_1bdf17da40fb4d8687456e5379af5da9",
      "value": " 125/125 [00:00&lt;00:00, 1.34kB/s]"
     }
    },
    "a7e27116c7b04f5e8980ea29c59bd9ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a840d7d2dc0042c1955f064ef41e051d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abee545f24074d33a2a171f140d84ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07e6f8ff49d74ced96b87afaf99f52c0",
      "max": 778,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba9fc00d9d144278bcf944a9328d5d5f",
      "value": 778
     }
    },
    "b66c522257d04820932c9c7014392136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ba9fc00d9d144278bcf944a9328d5d5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c555968966fb402e9ed39c024476f34b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6407f5a50b34a0d9bfbd916ffb70d17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8b35d958ecc4f3683b86278b979f300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37dce533ad7648d0a09b3ef825c5aa31",
      "placeholder": "​",
      "style": "IPY_MODEL_e16a79b61af94733b44306e7b5444d29",
      "value": " 95.0/95.0 [00:00&lt;00:00, 3.19kB/s]"
     }
    },
    "cd89abbac71740c5a013481dd9129f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf11d66697d84676b9d8af11a2edd064": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d015260b083c40399f87d1a30be95f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d04e61e6abfe42b9afab583bcab66b92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d154e8e8a650447ab06425706d908f4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef762a4251b6405f8065c3e4ce880688",
      "placeholder": "​",
      "style": "IPY_MODEL_4d579e0c846b4e1bbc360d0ff2f2eccf",
      "value": "Downloading: 100%"
     }
    },
    "d2d78bbb74664973b1cde561152e9aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51b29673275343998567b43347eb591b",
      "placeholder": "​",
      "style": "IPY_MODEL_334e77a8b6284dfb886fefadea6998ca",
      "value": " 778/778 [00:00&lt;00:00, 26.3kB/s]"
     }
    },
    "dcb559ab088446f0a4cc9ae4720f8c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb8017bf12034a0297f17f0f3f5f1874",
      "placeholder": "​",
      "style": "IPY_MODEL_a840d7d2dc0042c1955f064ef41e051d",
      "value": " 93.0/93.0 [00:00&lt;00:00, 3.23kB/s]"
     }
    },
    "e16a79b61af94733b44306e7b5444d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e499b443a3964dc2bca05692abde2dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebb2f370c71a470895096be1ab1eadbf",
      "max": 134360208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7e27116c7b04f5e8980ea29c59bd9ce",
      "value": 134360208
     }
    },
    "eb8017bf12034a0297f17f0f3f5f1874": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebb2f370c71a470895096be1ab1eadbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef762a4251b6405f8065c3e4ce880688": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f0b29c16df48f798dbdabc99207f2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a00dda470ef4f0893676c794e006a8f",
      "placeholder": "​",
      "style": "IPY_MODEL_0c9bd61e2e904fdaa4f578c19c0f6ea9",
      "value": "Downloading: 100%"
     }
    },
    "fb9ce840b4644d6eab03736688e57e23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d015260b083c40399f87d1a30be95f4f",
      "max": 93,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c555968966fb402e9ed39c024476f34b",
      "value": 93
     }
    },
    "fc1cf1de39dc45d69551ca2ca401a447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fefc4de84c7847bf88635bfcad3a5f9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
