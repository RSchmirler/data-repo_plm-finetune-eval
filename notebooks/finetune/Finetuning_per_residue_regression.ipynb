{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876db82e",
   "metadata": {},
   "source": [
    "# Prot T5 Finetuning\n",
    "# per residue regression\n",
    "\n",
    "This notebook allows you to finetune PLMs to your own datasets\n",
    "\n",
    "For better perfomance we apply [Parameter-Efficient Fine-Tuning (PEFT)](https://huggingface.co/blog/peft). For this we apply [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685).\n",
    "\n",
    "The core training loop is implemented with the pytorch [huggingface trainer](https://huggingface.co/docs/transformers/main_classes/trainer).\n",
    "\n",
    "In case it is needed for higher memory efficiency, we utilize the [deepspeed](https://github.com/microsoft/DeepSpeed) implementation of [huggingface](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5ec35",
   "metadata": {},
   "source": [
    "## Imports and env. variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "angry-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os.path\n",
    "os.chdir(\"set working path here\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers.models.esm.modeling_esm import EsmPreTrainedModel, EsmModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# for custom DataCollator\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "import peft\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, inject_adapter_in_model, LoraConfig\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8534fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables to run Deepspeed from a notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9992\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bb08d",
   "metadata": {},
   "source": [
    "# Environment to run this notebook\n",
    "\n",
    "\n",
    "These are the versions of the core packages we use to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35bdadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  1.13.1\n",
      "Cuda version:  11.7\n",
      "Numpy version:  1.22.3\n",
      "Pandas version:  2.0.3\n",
      "Transformers version:  4.26.1\n",
      "Datasets version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109a4d7",
   "metadata": {},
   "source": [
    "**For easy setup of this environment you can use the finetuning.yml File provided in this folder**\n",
    "\n",
    "check here for [setting up env from a yml File](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259308dc",
   "metadata": {},
   "source": [
    "# Valid Model checkpoints\n",
    "\n",
    "This notebook was tested with all models mentioned below.\n",
    "All required, model specific adaptations will be taken care of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc90c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESMs = [\"facebook/esm2_t6_8M_UR50D\",\n",
    "         \"facebook/esm2_t12_35M_UR50D\",\n",
    "         \"facebook/esm2_t30_150M_UR50D\",\n",
    "         \"facebook/esm2_t33_650M_UR50D\",\n",
    "         \"facebook/esm2_t36_3B_UR50D\"]\n",
    "\n",
    "T5s = [\"Rostlab/prot_t5_xl_uniref50\",\n",
    "       'Rostlab/ProstT5',\n",
    "       \"ElnaggarLab/ankh-base\",\n",
    "       \"ElnaggarLab/ankh-large\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06975d",
   "metadata": {},
   "source": [
    "### Select your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3237a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = T5s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2dda19",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "Provide your training and validation data in seperate pandas dataframes \n",
    "\n",
    "example shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c012178",
   "metadata": {},
   "source": [
    "**Modify the data loading part as needed for your data**\n",
    "\n",
    "To run the training you need two dataframes (training and validation) each with the columns \"sequence\" and \"label\"\n",
    "\n",
    "Columns are:\n",
    "+ protein sequence\n",
    "+ label is a list of len(protein sequence) with float numbers corresponding to predicted regression value at this position.\n",
    "  If you want to ignore certain positions during training, put a -100 in label at the corresponding positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a10d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example we import the disorder dataset from https://github.com/DagmarIlz/SETH/\n",
    "# For details, see publication here: https://www.frontiersin.org/articles/10.3389/fbinf.2022.1019597/full\n",
    "\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84e2021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26672</td>\n",
       "      <td>MASNDYTQQATQSYGAYPTQPGQGYSQQSSQPYGQQSYSGYSQSTD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26654</td>\n",
       "      <td>GTRGDADMYDLPKKEDALLYQSKGYNDDYYEESYFTTRTYGEPESA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25586</td>\n",
       "      <td>SLTLNLITEMGRLPTFMTQKARDALDNLAVLHTAEAGGRAYNHALSEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25399</td>\n",
       "      <td>RLDKQGNFNAWVAGSYGNDQWLQVDLGSSKEVTGIITQGARNFGSV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25185</td>\n",
       "      <td>MGTSAPNNTNNANSSITPAFGSNNTGNTAFGNSNPTSNVFGSNNST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                           sequence\n",
       "0  26672  MASNDYTQQATQSYGAYPTQPGQGYSQQSSQPYGQQSYSGYSQSTD...\n",
       "1  26654  GTRGDADMYDLPKKEDALLYQSKGYNDDYYEESYFTTRTYGEPESA...\n",
       "2  25586   SLTLNLITEMGRLPTFMTQKARDALDNLAVLHTAEAGGRAYNHALSEL\n",
       "3  25399  RLDKQGNFNAWVAGSYGNDQWLQVDLGSSKEVTGIITQGARNFGSV...\n",
       "4  25185  MGTSAPNNTNNANSSITPAFGSNNTGNTAFGNSNPTSNVFGSNNST..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training sequences\n",
    "url = \"https://raw.githubusercontent.com/DagmarIlz/SETH/main/datasets/CheZOD1174_training_set_sequences.fasta\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Create a StringIO object to simulate a file-like object\n",
    "fasta_file = StringIO(response.text)\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "sequences = []\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    sequences.append([record.name, str(record.seq)])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0c81ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Load training labels (CheZOD_scores)\n",
    "url = \"https://raw.githubusercontent.com/DagmarIlz/SETH/main/datasets/CheZOD1174_training_set_CheZOD_scores.txt\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "lines = response.text.splitlines()\n",
    "\n",
    "names=[]\n",
    "labels=[]\n",
    "\n",
    "# Split each line into name and label\n",
    "for l in lines:\n",
    "    names.append(l.split(\":\\t\")[0])\n",
    "    labels.append(l.split(\":\\t\")[1].split(\", \"))\n",
    "\n",
    "# Covert labels to float values\n",
    "for l in range(0,len(labels)):\n",
    "    labels[l]=[float(label) for label in labels[l]]\n",
    "    \n",
    "# check if sequence names match\n",
    "print(list(df.name) == names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7921649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation dataframes\n",
    "\n",
    "# Add label column\n",
    "df[\"label\"] = labels\n",
    "# drop name column\n",
    "df = df [[\"sequence\", \"label\"]]\n",
    "\n",
    "# Split of 10% of training data as validation split\n",
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train.reset_index(drop=True,inplace=True)\n",
    "valid.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Replace invalid labels (>900) with -100 (will be ignored by pytorch loss)\n",
    "train['label'] = train.apply(lambda row:  [-100 if x > 900 else x for x in row['label']], axis=1)\n",
    "valid['label'] = valid.apply(lambda row:  [-100 if x > 900 else x for x in row['label']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef99ea6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GVGETKVIYHLDEEETPYLVKIPVPAERITLGDFKSVLQRPAGAKY...</td>\n",
       "      <td>[-100, 3.219, 4.014, 3.745, 3.53, 2.301, 3.204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSSGSSGRKKPVSQSLEFPTRYSPYRPYRCVHQGCFAAFTIQQNLI...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -2.194, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIHKQKEKSRLQGGVLVNEILNHMKRATQIPSYKKLIMY</td>\n",
       "      <td>[-100, 6.476, 6.296, 7.407, 5.346, 5.509, 4.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGMIVFVRFNSSYGFPVEVDSDTSILQLKEVVAKRQGVPADQLRVI...</td>\n",
       "      <td>[-100, 9.189, 10.389, 12.882, 12.002, 14.043, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVLQVLHIPDERLRKVAKPVEEVNAEIQRIVDDMFETMYAEEGIGL...</td>\n",
       "      <td>[-100, 9.978, 12.505, 13.381, 13.069, 13.551, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  GVGETKVIYHLDEEETPYLVKIPVPAERITLGDFKSVLQRPAGAKY...   \n",
       "1  GSSGSSGRKKPVSQSLEFPTRYSPYRPYRCVHQGCFAAFTIQQNLI...   \n",
       "2            GIHKQKEKSRLQGGVLVNEILNHMKRATQIPSYKKLIMY   \n",
       "3  MGMIVFVRFNSSYGFPVEVDSDTSILQLKEVVAKRQGVPADQLRVI...   \n",
       "4  SVLQVLHIPDERLRKVAKPVEEVNAEIQRIVDDMFETMYAEEGIGL...   \n",
       "\n",
       "                                               label  \n",
       "0  [-100, 3.219, 4.014, 3.745, 3.53, 2.301, 3.204...  \n",
       "1  [-100, -100, -100, -100, -100, -100, -2.194, -...  \n",
       "2  [-100, 6.476, 6.296, 7.407, 5.346, 5.509, 4.99...  \n",
       "3  [-100, 9.189, 10.389, 12.882, 12.002, 14.043, ...  \n",
       "4  [-100, 9.978, 12.505, 13.381, 13.069, 13.551, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8846e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ETGDIVETATGAGSFTTLLTAAEAAGLVDTLKGDGPFTVFAPTDAA...</td>\n",
       "      <td>[-100, 8.323, 10.063, 11.146, 12.718, 13.846, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSSGSSGEGLDYLTAPNPPSIREELCTASHDTITVHWISDDEFSIS...</td>\n",
       "      <td>[-100, -100, -100, -100, -0.834, -1.46, -0.909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAMGMSVADFYGSNVEVLLNNDSKARGVITNFDSSNSILQLRLAND...</td>\n",
       "      <td>[-100, -100, -100, -100, 5.854, 9.065, 12.211,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGSSHHHHHHSSHMLVPRGSSKNPLLGKKRALLLSEPSLLRTVQQI...</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSSLQNNQDVSFENIQWSIDPGADLSQYKMDVTVIDTKDGSQSKLG...</td>\n",
       "      <td>[-100, -100, 3.71, 4.443, 6.613, 5.956, 5.117,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  ETGDIVETATGAGSFTTLLTAAEAAGLVDTLKGDGPFTVFAPTDAA...   \n",
       "1  GSSGSSGEGLDYLTAPNPPSIREELCTASHDTITVHWISDDEFSIS...   \n",
       "2  GAMGMSVADFYGSNVEVLLNNDSKARGVITNFDSSNSILQLRLAND...   \n",
       "3  MGSSHHHHHHSSHMLVPRGSSKNPLLGKKRALLLSEPSLLRTVQQI...   \n",
       "4  GSSLQNNQDVSFENIQWSIDPGADLSQYKMDVTVIDTKDGSQSKLG...   \n",
       "\n",
       "                                               label  \n",
       "0  [-100, 8.323, 10.063, 11.146, 12.718, 13.846, ...  \n",
       "1  [-100, -100, -100, -100, -0.834, -1.46, -0.909...  \n",
       "2  [-100, -100, -100, -100, 5.854, 9.065, 12.211,...  \n",
       "3  [-100, -100, -100, -100, -100, -100, -100, -10...  \n",
       "4  [-100, -100, 3.71, 4.443, 6.613, 5.956, 5.117,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b996723",
   "metadata": {},
   "source": [
    "# Models and Low Rank Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df0111",
   "metadata": {},
   "source": [
    "## T5 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-channels",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Regression model definition \n",
    "\n",
    "adding a token regression head on top of the encoder model\n",
    "\n",
    "modified from [EsmForTokenClassification](https://github.com/huggingface/transformers/blob/v4.30.0/src/transformers/models/esm/modeling_esm.py#L1178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acting-archives",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.2, num_labels=1):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderForTokenRegression(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = MSELoss()\n",
    "\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1)\n",
    "\n",
    "            active_labels = torch.where(\n",
    "              active_loss, labels.view(-1), torch.tensor(-100).type_as(labels)\n",
    "            )\n",
    "\n",
    "            valid_logits=active_logits[active_labels!=-100]\n",
    "            valid_labels=active_labels[active_labels!=-100]\n",
    "\n",
    "            loss = loss_fct(valid_logits, valid_labels)\n",
    "            \n",
    "        \n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13666f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### T5 Data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf601446",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# based on transformers DataCollatorForTokenClassification\n",
    "@dataclass\n",
    "class DataCollatorForTokenRegression_t5(DataCollatorMixin):\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "    Args:\n",
    "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
    "            The tokenizer used for encoding the data.\n",
    "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence is provided).\n",
    "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
    "              acceptable input length for the model if that argument is not provided.\n",
    "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
    "        max_length (`int`, *optional*):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (`int`, *optional*):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        label_pad_token_id (`int`, *optional*, defaults to -100):\n",
    "            The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions).\n",
    "        return_tensors (`str`):\n",
    "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def torch_call(self, features):\n",
    "        import torch\n",
    "\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature[label_name] for feature in features] if label_name in features[0].keys() else None\n",
    "\n",
    "        no_labels_features = [{k: v for k, v in feature.items() if k != label_name} for feature in features]\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            no_labels_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        if labels is None:\n",
    "            return batch\n",
    "\n",
    "        sequence_length = batch[\"input_ids\"].shape[1]\n",
    "        padding_side = self.tokenizer.padding_side\n",
    "\n",
    "        def to_list(tensor_or_iterable):\n",
    "            if isinstance(tensor_or_iterable, torch.Tensor):\n",
    "                return tensor_or_iterable.tolist()\n",
    "            return list(tensor_or_iterable)\n",
    "\n",
    "        if padding_side == \"right\":\n",
    "            batch[label_name] = [\n",
    "                to_list(label) + [self.label_pad_token_id] * (sequence_length - len(label)) for label in labels\n",
    "                ]\n",
    "        else:\n",
    "            batch[label_name] = [\n",
    "                [self.label_pad_token_id] * (sequence_length - len(label)) + to_list(label) for label in labels\n",
    "                ]\n",
    "        # change datatype from torch.int64 to torch.float\n",
    "        batch[label_name] = torch.tensor(batch[label_name], dtype=torch.float)\n",
    "        return batch\n",
    "\n",
    "def _torch_collate_batch(examples, tokenizer, pad_to_multiple_of: Optional[int] = None):\n",
    "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
    "    import torch\n",
    "\n",
    "    # Tensorize if necessary.\n",
    "    if isinstance(examples[0], (list, tuple, np.ndarray)):\n",
    "        examples = [torch.tensor(e, dtype=torch.long) for e in examples]\n",
    "\n",
    "    length_of_first = examples[0].size(0)\n",
    "\n",
    "    # Check if padding is necessary.\n",
    "\n",
    "    are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
    "    if are_tensors_same_length and (pad_to_multiple_of is None or length_of_first % pad_to_multiple_of == 0):\n",
    "        return torch.stack(examples, dim=0)\n",
    "\n",
    "    # If yes, check if we have a `pad_token`.\n",
    "    if tokenizer._pad_token is None:\n",
    "        raise ValueError(\n",
    "            \"You are attempting to pad samples but the tokenizer you are using\"\n",
    "            f\" ({tokenizer.__class__.__name__}) does not have a pad token.\"\n",
    "        )\n",
    "\n",
    "    # Creating the full tensor and filling it with our data.\n",
    "    max_length = max(x.size(0) for x in examples)\n",
    "    if pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
    "        max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
    "    result = examples[0].new_full([len(examples), max_length], tokenizer.pad_token_id)\n",
    "    for i, example in enumerate(examples):\n",
    "        if tokenizer.padding_side == \"right\":\n",
    "            result[i, : example.shape[0]] = example\n",
    "        else:\n",
    "            result[i, -example.shape[0] :] = example\n",
    "    return result\n",
    "\n",
    "def tolist(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif hasattr(x, \"numpy\"):  # Checks for TF tensors without needing the import\n",
    "        x = x.numpy()\n",
    "    return x.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0e217",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load T5 model\n",
    "this creates a T5 model with prediction head and LoRA modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "split-austin",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_T5_model_regression(checkpoint, half_precision, full=False, deepspeed=True):\n",
    "    # Load model and tokenizer\n",
    "\n",
    "    if \"ankh\" in checkpoint :\n",
    "        model = T5EncoderModel.from_pretrained(checkpoint)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    elif \"prot_t5\" in checkpoint:\n",
    "        # possible to load the half precision model (thanks to @pawel-rezo for pointing that out)\n",
    "        if half_precision and deepspeed : \n",
    "            tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "            model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\", torch_dtype=torch.float16)#.to(torch.device('cuda')\n",
    "        else:\n",
    "            model = T5EncoderModel.from_pretrained(checkpoint)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "                \n",
    "    elif \"ProstT5\" in checkpoint:\n",
    "        if half_precision and deepspeed: \n",
    "            tokenizer = T5Tokenizer.from_pretrained(checkpoint, do_lower_case=False)\n",
    "            model = T5EncoderModel.from_pretrained(checkpoint, torch_dtype=torch.float16)#.to(torch.device('cuda')\n",
    "        else:\n",
    "            model = T5EncoderModel.from_pretrained(checkpoint)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    \n",
    "    # Create new Regression model with correct dimensions\n",
    "    class_config=ClassConfig(num_labels = 1)\n",
    "    class_model=T5EncoderForTokenRegression(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    if full == True:\n",
    "        return model, tokenizer \n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"T5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # lora modification\n",
    "    peft_config = LoraConfig(\n",
    "        r=4, lora_alpha=1, bias=\"all\", target_modules=[\"q\",\"k\",\"v\",\"o\"]\n",
    "    )\n",
    "    \n",
    "    model = inject_adapter_in_model(peft_config, model)\n",
    "    \n",
    "    # Unfreeze the prediction head\n",
    "    for (param_name, param) in model.classifier.named_parameters():\n",
    "                param.requires_grad = True \n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"T5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fea04f",
   "metadata": {},
   "source": [
    "## ESM2 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3e5cf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Regression model definition\n",
    "\n",
    "adding a token regression head on top of the encoder model\n",
    "\n",
    "modified from [EsmForTokenClassification](https://github.com/huggingface/transformers/blob/v4.30.0/src/transformers/models/esm/modeling_esm.py#L1178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a411186",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EsmForTokenRegression(EsmPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.esm = EsmModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.esm(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = MSELoss()\n",
    "\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1)\n",
    "\n",
    "            active_labels = torch.where(\n",
    "              active_loss, labels.view(-1), torch.tensor(-100).type_as(labels)\n",
    "            )\n",
    "\n",
    "            valid_logits=active_logits[active_labels!=-100]\n",
    "            valid_labels=active_labels[active_labels!=-100]\n",
    "\n",
    "            loss = loss_fct(valid_logits, valid_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7596c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ESM2 Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb44cde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# based on transformers DataCollatorForTokenClassification\n",
    "@dataclass\n",
    "class DataCollatorForTokenRegression_esm(DataCollatorMixin):\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "    Args:\n",
    "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
    "            The tokenizer used for encoding the data.\n",
    "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence is provided).\n",
    "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
    "              acceptable input length for the model if that argument is not provided.\n",
    "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
    "        max_length (`int`, *optional*):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (`int`, *optional*):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        label_pad_token_id (`int`, *optional*, defaults to -100):\n",
    "            The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions).\n",
    "        return_tensors (`str`):\n",
    "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def torch_call(self, features):\n",
    "        import torch\n",
    "\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature[label_name] for feature in features] if label_name in features[0].keys() else None\n",
    "\n",
    "        no_labels_features = [{k: v for k, v in feature.items() if k != label_name} for feature in features]\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            no_labels_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        if labels is None:\n",
    "            return batch\n",
    "\n",
    "        sequence_length = batch[\"input_ids\"].shape[1]\n",
    "        padding_side = self.tokenizer.padding_side\n",
    "\n",
    "        def to_list(tensor_or_iterable):\n",
    "            if isinstance(tensor_or_iterable, torch.Tensor):\n",
    "                return tensor_or_iterable.tolist()\n",
    "            return list(tensor_or_iterable)\n",
    "\n",
    "        if padding_side == \"right\": \n",
    "            # changed to pad the special tokens at the beginning and end of the sequence\n",
    "            batch[label_name] = [\n",
    "                [self.label_pad_token_id] + to_list(label) + [self.label_pad_token_id] * (sequence_length - len(label)-1) for label in labels\n",
    "                ]                \n",
    "        else:\n",
    "            batch[label_name] = [\n",
    "                [self.label_pad_token_id] * (sequence_length - len(label)) + to_list(label) for label in labels\n",
    "                ]\n",
    "        # change datatype from torch.int64 to torch.float\n",
    "        batch[label_name] = torch.tensor(batch[label_name], dtype=torch.float)\n",
    "        return batch\n",
    "\n",
    "def _torch_collate_batch(examples, tokenizer, pad_to_multiple_of: Optional[int] = None):\n",
    "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
    "    import torch\n",
    "\n",
    "    # Tensorize if necessary.\n",
    "    if isinstance(examples[0], (list, tuple, np.ndarray)):\n",
    "        examples = [torch.tensor(e, dtype=torch.long) for e in examples]\n",
    "\n",
    "    length_of_first = examples[0].size(0)\n",
    "\n",
    "    # Check if padding is necessary.\n",
    "\n",
    "    are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
    "    if are_tensors_same_length and (pad_to_multiple_of is None or length_of_first % pad_to_multiple_of == 0):\n",
    "        return torch.stack(examples, dim=0)\n",
    "\n",
    "    # If yes, check if we have a `pad_token`.\n",
    "    if tokenizer._pad_token is None:\n",
    "        raise ValueError(\n",
    "            \"You are attempting to pad samples but the tokenizer you are using\"\n",
    "            f\" ({tokenizer.__class__.__name__}) does not have a pad token.\"\n",
    "        )\n",
    "\n",
    "    # Creating the full tensor and filling it with our data.\n",
    "    max_length = max(x.size(0) for x in examples)\n",
    "    if pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
    "        max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
    "    result = examples[0].new_full([len(examples), max_length], tokenizer.pad_token_id)\n",
    "    for i, example in enumerate(examples):\n",
    "        if tokenizer.padding_side == \"right\":\n",
    "            result[i, : example.shape[0]] = example\n",
    "        else:\n",
    "            result[i, -example.shape[0] :] = example\n",
    "    return result\n",
    "\n",
    "def tolist(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif hasattr(x, \"numpy\"):  # Checks for TF tensors without needing the import\n",
    "        x = x.numpy()\n",
    "    return x.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885beb7",
   "metadata": {},
   "source": [
    "### Load ESM2 Model\n",
    "\n",
    "this creates a ESM2 model with prediction head and LoRA modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30e29248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ESM2 models\n",
    "def load_esm_model_regression(checkpoint, half_precision, full = False, deepspeed=True):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    \n",
    "    if half_precision and deepspeed:\n",
    "        model = EsmForTokenRegression.from_pretrained(checkpoint, num_labels = 1, torch_dtype = torch.float16)\n",
    "    else:\n",
    "        model = EsmForTokenRegression.from_pretrained(checkpoint, num_labels = 1)\n",
    "        \n",
    "    if full == True:\n",
    "        return model, tokenizer \n",
    "        \n",
    "    peft_config = LoraConfig(\n",
    "        r=4, lora_alpha=1, bias=\"all\", target_modules=[\"query\",\"key\",\"value\",\"dense\"]\n",
    "    )\n",
    "    \n",
    "    model = inject_adapter_in_model(peft_config, model) \n",
    "    \n",
    "    # Unfreeze the prediction head\n",
    "    for (param_name, param) in model.classifier.named_parameters():\n",
    "                param.requires_grad = True \n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-yeast",
   "metadata": {},
   "source": [
    "# Training Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735e819",
   "metadata": {},
   "source": [
    "## Deepspeed config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eed91c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92962861",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "liberal-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels,checkpoint):\n",
    "    \n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    \n",
    "    if (\"esm\" in checkpoint) or (\"ProstT5\" in checkpoint):\n",
    "        # we need to cut of labels after 1022 positions for the data collator to add the correct padding (1022 + 2 special tokens)\n",
    "        labels = [l[:1022] for l in labels]         \n",
    "    else:\n",
    "        # we need to cut of labels after 1023 positions for the data collator to add the correct padding (1023 + 1 special tokens)\n",
    "        labels = [l[:1023] for l in labels]\n",
    "        \n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "     \n",
    "    return dataset\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_residue(\n",
    "        checkpoint,       #model checkpoint\n",
    "    \n",
    "        train_df,         #training data\n",
    "        valid_df,         #validation data      \n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch = 4,        #for training\n",
    "        accum = 2,        #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs = 10,      #training epochs\n",
    "        lr = 3e-4,        #recommended learning rate\n",
    "        seed = 42,        #random seed\n",
    "        deepspeed = False,#if gpu is large enough disable deepspeed for training speedup\n",
    "        mixed = True,     #enable mixed precision training\n",
    "        full = False,     #enable training of the full model (instead of LoRA)\n",
    "        gpu = 1 ):        #gpu selection (1 for first gpu)\n",
    "\n",
    "    print(\"Model used:\", checkpoint, \"\\n\")\n",
    "    \n",
    "    # Correct incompatible training settings\n",
    "    if \"ankh\" in checkpoint and mixed:\n",
    "        print(\"Ankh models do not support mixed precision training!\")\n",
    "        print(\"switched to FULL PRECISION TRAINING instead\")\n",
    "        mixed = False\n",
    "        \n",
    "    \n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    if \"esm\" in checkpoint:\n",
    "        model, tokenizer = load_esm_model_regression(checkpoint, mixed, full, deepspeed)\n",
    "    else:\n",
    "        model, tokenizer = load_T5_model_regression(checkpoint, mixed, full, deepspeed)\n",
    "\n",
    "    # Preprocess inputs\n",
    "    # Replace uncommon AAs with \"X\"\n",
    "    train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "    valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "    \n",
    "    # Add spaces between each amino acid for ProtT5 and ProstT5 to correctly use them\n",
    "    if \"Rostlab\" in checkpoint:\n",
    "        train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "        valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "        \n",
    "    # Add <AA2fold> for ProstT5 to inform the model of the input type (amino acid sequence here)\n",
    "    if \"ProstT5\" in checkpoint:    \n",
    "        train_df['sequence']=train_df.apply(lambda row : \"<AA2fold> \" + row[\"sequence\"], axis = 1)  \n",
    "        valid_df['sequence']=valid_df.apply(lambda row : \"<AA2fold> \" + row[\"sequence\"], axis = 1)\n",
    "\n",
    "    # Create Datasets\n",
    "    train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']),checkpoint)\n",
    "    valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']),checkpoint)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    args = TrainingArguments(\n",
    "        \"./scripts/Finetuning/PT5/\",\n",
    "        evaluation_strategy = \"steps\",\n",
    "        eval_steps = 528,\n",
    "        logging_strategy = \"epoch\",\n",
    "        save_strategy = \"no\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch,\n",
    "        #per_device_eval_batch_size=val_batch,\n",
    "        per_device_eval_batch_size=batch,\n",
    "        gradient_accumulation_steps=accum,\n",
    "        num_train_epochs=epochs,\n",
    "        seed = seed,\n",
    "        deepspeed= ds_config if deepspeed else None,\n",
    "        fp16 = mixed,\n",
    "    ) \n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "\n",
    "        metric = load(\"spearmanr\")\n",
    "        predictions, labels = eval_pred\n",
    "        predictions=predictions.flatten()\n",
    "        labels=labels.flatten()\n",
    "\n",
    "        valid_labels=labels[np.where((labels != -100 ) & (labels < 900 ))]\n",
    "        valid_predictions=predictions[np.where((labels != -100 ) & (labels < 900 ))]\n",
    "\n",
    "        return metric.compute(predictions=valid_predictions, references=valid_labels)\n",
    "\n",
    "    # For token regression we need a data collator here to pad correctly\n",
    "    # For esm2 and Prost pad at the beginning and at the end\n",
    "    if (\"esm\" in checkpoint) or (\"ProstT5\" in checkpoint):\n",
    "        data_collator = DataCollatorForTokenRegression_esm(tokenizer) \n",
    "    # For Ankh and ProtT5 pad only at the end\n",
    "    else:\n",
    "        data_collator = DataCollatorForTokenRegression_t5(tokenizer)        \n",
    "\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=valid_set,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )    \n",
    "    \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac94ab1",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede09d5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83fd6b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: Rostlab/prot_t5_xl_uniref50 \n",
      "\n",
      "T5_Classfier\n",
      "Trainable Parameter: 1208142849\n",
      "T5_LoRA_Classfier\n",
      "Trainable Parameter: 1968129\n",
      "\n",
      "[2024-04-23 11:58:11,871] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 11:58:12,145] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed info: version=0.8.1, git-hash=unknown, git-branch=unknown\n",
      "[2024-04-23 11:58:13,577] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-04-23 11:58:14,827] [WARNING] [cpu_adam.py:83:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /homes/schmirx6/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /homes/schmirx6/.cache/torch_extensions/py39_cu117/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 3.0478157997131348 seconds\n",
      "[2024-04-23 11:58:19,632] [INFO] [logging.py:75:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2024-04-23 11:58:19,646] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2024-04-23 11:58:19,647] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2024-04-23 11:58:19,647] [INFO] [logging.py:75:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2024-04-23 11:58:19,648] [INFO] [stage_1_and_2.py:144:__init__] Reduce bucket size 200000000\n",
      "[2024-04-23 11:58:19,648] [INFO] [stage_1_and_2.py:145:__init__] Allgather bucket size 200000000\n",
      "[2024-04-23 11:58:19,648] [INFO] [stage_1_and_2.py:146:__init__] CPU Offload: True\n",
      "[2024-04-23 11:58:19,649] [INFO] [stage_1_and_2.py:147:__init__] Round robin gradient partitioning: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /homes/schmirx6/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "Emitting ninja build file /homes/schmirx6/.cache/torch_extensions/py39_cu117/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load utils op: 0.44225049018859863 seconds\n",
      "Rank: 0 partition count [1] and sizes[(1968130, False)] \n",
      "[2024-04-23 11:58:20,333] [INFO] [utils.py:825:see_memory_usage] Before initializing optimizer states\n",
      "[2024-04-23 11:58:20,334] [INFO] [utils.py:826:see_memory_usage] MA 2.25 GB         Max_MA 2.25 GB         CA 2.44 GB         Max_CA 2 GB \n",
      "[2024-04-23 11:58:20,334] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 42.69 GB, percent = 22.9%\n",
      "[2024-04-23 11:58:20,515] [INFO] [utils.py:825:see_memory_usage] After initializing optimizer states\n",
      "[2024-04-23 11:58:20,517] [INFO] [utils.py:826:see_memory_usage] MA 2.25 GB         Max_MA 2.25 GB         CA 2.44 GB         Max_CA 2 GB \n",
      "[2024-04-23 11:58:20,518] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 42.71 GB, percent = 22.9%\n",
      "[2024-04-23 11:58:20,518] [INFO] [stage_1_and_2.py:527:__init__] optimizer state initialized\n",
      "[2024-04-23 11:58:20,675] [INFO] [utils.py:825:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-04-23 11:58:20,676] [INFO] [utils.py:826:see_memory_usage] MA 2.25 GB         Max_MA 2.25 GB         CA 2.44 GB         Max_CA 2 GB \n",
      "[2024-04-23 11:58:20,677] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 42.71 GB, percent = 22.9%\n",
      "[2024-04-23 11:58:20,682] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2024-04-23 11:58:20,682] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2024-04-23 11:58:20,682] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f430ecd72b0>\n",
      "[2024-04-23 11:58:20,683] [INFO] [logging.py:75:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 11:58:20,685] [INFO] [config.py:1009:print] DeepSpeedEngine configuration:\n",
      "[2024-04-23 11:58:20,686] [INFO] [config.py:1013:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-04-23 11:58:20,686] [INFO] [config.py:1013:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-04-23 11:58:20,687] [INFO] [config.py:1013:print]   amp_enabled .................. False\n",
      "[2024-04-23 11:58:20,687] [INFO] [config.py:1013:print]   amp_params ................... False\n",
      "[2024-04-23 11:58:20,688] [INFO] [config.py:1013:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-04-23 11:58:20,688] [INFO] [config.py:1013:print]   bfloat16_enabled ............. False\n",
      "[2024-04-23 11:58:20,688] [INFO] [config.py:1013:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-04-23 11:58:20,689] [INFO] [config.py:1013:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-04-23 11:58:20,689] [INFO] [config.py:1013:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-04-23 11:58:20,689] [INFO] [config.py:1013:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f430f02eeb0>\n",
      "[2024-04-23 11:58:20,689] [INFO] [config.py:1013:print]   communication_data_type ...... None\n",
      "[2024-04-23 11:58:20,690] [INFO] [config.py:1013:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-04-23 11:58:20,690] [INFO] [config.py:1013:print]   curriculum_enabled_legacy .... False\n",
      "[2024-04-23 11:58:20,690] [INFO] [config.py:1013:print]   curriculum_params_legacy ..... False\n",
      "[2024-04-23 11:58:20,691] [INFO] [config.py:1013:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-04-23 11:58:20,691] [INFO] [config.py:1013:print]   data_efficiency_enabled ...... False\n",
      "[2024-04-23 11:58:20,691] [INFO] [config.py:1013:print]   dataloader_drop_last ......... False\n",
      "[2024-04-23 11:58:20,692] [INFO] [config.py:1013:print]   disable_allgather ............ False\n",
      "[2024-04-23 11:58:20,692] [INFO] [config.py:1013:print]   dump_state ................... False\n",
      "[2024-04-23 11:58:20,692] [INFO] [config.py:1013:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2024-04-23 11:58:20,695] [INFO] [config.py:1013:print]   eigenvalue_enabled ........... False\n",
      "[2024-04-23 11:58:20,695] [INFO] [config.py:1013:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-04-23 11:58:20,695] [INFO] [config.py:1013:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-04-23 11:58:20,696] [INFO] [config.py:1013:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-04-23 11:58:20,696] [INFO] [config.py:1013:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-04-23 11:58:20,696] [INFO] [config.py:1013:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-04-23 11:58:20,697] [INFO] [config.py:1013:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-04-23 11:58:20,697] [INFO] [config.py:1013:print]   eigenvalue_verbose ........... False\n",
      "[2024-04-23 11:58:20,698] [INFO] [config.py:1013:print]   elasticity_enabled ........... False\n",
      "[2024-04-23 11:58:20,698] [INFO] [config.py:1013:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-04-23 11:58:20,699] [INFO] [config.py:1013:print]   fp16_auto_cast ............... False\n",
      "[2024-04-23 11:58:20,699] [INFO] [config.py:1013:print]   fp16_enabled ................. True\n",
      "[2024-04-23 11:58:20,699] [INFO] [config.py:1013:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-04-23 11:58:20,700] [INFO] [config.py:1013:print]   global_rank .................. 0\n",
      "[2024-04-23 11:58:20,700] [INFO] [config.py:1013:print]   grad_accum_dtype ............. None\n",
      "[2024-04-23 11:58:20,700] [INFO] [config.py:1013:print]   gradient_accumulation_steps .. 1\n",
      "[2024-04-23 11:58:20,701] [INFO] [config.py:1013:print]   gradient_clipping ............ 1.0\n",
      "[2024-04-23 11:58:20,701] [INFO] [config.py:1013:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-04-23 11:58:20,701] [INFO] [config.py:1013:print]   initial_dynamic_scale ........ 65536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 11:58:20,702] [INFO] [config.py:1013:print]   load_universal_checkpoint .... False\n",
      "[2024-04-23 11:58:20,702] [INFO] [config.py:1013:print]   loss_scale ................... 0\n",
      "[2024-04-23 11:58:20,702] [INFO] [config.py:1013:print]   memory_breakdown ............. False\n",
      "[2024-04-23 11:58:20,703] [INFO] [config.py:1013:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-04-23 11:58:20,703] [INFO] [config.py:1013:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-04-23 11:58:20,703] [INFO] [config.py:1013:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-04-23 11:58:20,704] [INFO] [config.py:1013:print]   optimizer_name ............... adamw\n",
      "[2024-04-23 11:58:20,704] [INFO] [config.py:1013:print]   optimizer_params ............. {'lr': 0.0003, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2024-04-23 11:58:20,704] [INFO] [config.py:1013:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2024-04-23 11:58:20,705] [INFO] [config.py:1013:print]   pld_enabled .................. False\n",
      "[2024-04-23 11:58:20,705] [INFO] [config.py:1013:print]   pld_params ................... False\n",
      "[2024-04-23 11:58:20,705] [INFO] [config.py:1013:print]   prescale_gradients ........... False\n",
      "[2024-04-23 11:58:20,706] [INFO] [config.py:1013:print]   scheduler_name ............... WarmupLR\n",
      "[2024-04-23 11:58:20,706] [INFO] [config.py:1013:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.0003, 'warmup_num_steps': 0}\n",
      "[2024-04-23 11:58:20,706] [INFO] [config.py:1013:print]   sparse_attention ............. None\n",
      "[2024-04-23 11:58:20,707] [INFO] [config.py:1013:print]   sparse_gradients_enabled ..... False\n",
      "[2024-04-23 11:58:20,707] [INFO] [config.py:1013:print]   steps_per_print .............. 2000\n",
      "[2024-04-23 11:58:20,707] [INFO] [config.py:1013:print]   train_batch_size ............. 1\n",
      "[2024-04-23 11:58:20,708] [INFO] [config.py:1013:print]   train_micro_batch_size_per_gpu  1\n",
      "[2024-04-23 11:58:20,708] [INFO] [config.py:1013:print]   use_node_local_storage ....... False\n",
      "[2024-04-23 11:58:20,708] [INFO] [config.py:1013:print]   wall_clock_breakdown ......... False\n",
      "[2024-04-23 11:58:20,709] [INFO] [config.py:1013:print]   world_size ................... 1\n",
      "[2024-04-23 11:58:20,709] [INFO] [config.py:1013:print]   zero_allow_untested_optimizer  False\n",
      "[2024-04-23 11:58:20,709] [INFO] [config.py:1013:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
      "[2024-04-23 11:58:20,710] [INFO] [config.py:1013:print]   zero_enabled ................. True\n",
      "[2024-04-23 11:58:20,710] [INFO] [config.py:1013:print]   zero_optimization_stage ...... 2\n",
      "[2024-04-23 11:58:20,710] [INFO] [config.py:998:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.0003, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.0003, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /homes/schmirx6/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "***** Running training *****\n",
      "  Num examples = 1056\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load utils op: 0.003637075424194336 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10560\n",
      "  Number of trainable parameters = 1968129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000300, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2024-04-23 11:58:20,966] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10560' max='10560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10560/10560 44:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>No log</td>\n",
       "      <td>10.171875</td>\n",
       "      <td>0.738483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1056</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.484375</td>\n",
       "      <td>0.770201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1584</td>\n",
       "      <td>28.283100</td>\n",
       "      <td>8.914062</td>\n",
       "      <td>0.779922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2112</td>\n",
       "      <td>28.283100</td>\n",
       "      <td>9.492188</td>\n",
       "      <td>0.784870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>8.399000</td>\n",
       "      <td>8.382812</td>\n",
       "      <td>0.790989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3168</td>\n",
       "      <td>8.399000</td>\n",
       "      <td>9.093750</td>\n",
       "      <td>0.790046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3696</td>\n",
       "      <td>7.056900</td>\n",
       "      <td>9.960938</td>\n",
       "      <td>0.797240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4224</td>\n",
       "      <td>7.056900</td>\n",
       "      <td>8.546875</td>\n",
       "      <td>0.795736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4752</td>\n",
       "      <td>6.235900</td>\n",
       "      <td>8.617188</td>\n",
       "      <td>0.796103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5280</td>\n",
       "      <td>6.235900</td>\n",
       "      <td>7.781250</td>\n",
       "      <td>0.797253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5808</td>\n",
       "      <td>5.750200</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>0.799452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6336</td>\n",
       "      <td>5.750200</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>0.802791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6864</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>8.343750</td>\n",
       "      <td>0.803997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7392</td>\n",
       "      <td>5.270200</td>\n",
       "      <td>8.140625</td>\n",
       "      <td>0.805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7920</td>\n",
       "      <td>4.874700</td>\n",
       "      <td>8.609375</td>\n",
       "      <td>0.799161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8448</td>\n",
       "      <td>4.874700</td>\n",
       "      <td>7.996094</td>\n",
       "      <td>0.801349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8976</td>\n",
       "      <td>4.542400</td>\n",
       "      <td>8.515625</td>\n",
       "      <td>0.798665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9504</td>\n",
       "      <td>4.542400</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>0.805324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10032</td>\n",
       "      <td>4.384000</td>\n",
       "      <td>8.398438</td>\n",
       "      <td>0.801593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10560</td>\n",
       "      <td>4.384000</td>\n",
       "      <td>8.671875</td>\n",
       "      <td>0.803364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 11:58:21,187] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
      "[2024-04-23 11:58:21,407] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
      "[2024-04-23 11:58:21,628] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
      "[2024-04-23 11:58:21,850] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "[2024-04-23 11:58:22,071] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:01:47,218] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:06:00,306] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 512.0\n",
      "[2024-04-23 12:06:56,955] [INFO] [logging.py:75:log_dist] [Rank 0] step=2000, skipped=8, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:06:56,956] [INFO] [timer.py:198:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=4.190217918853299, CurrSamplesPerSec=4.351145386605585, MemAllocated=2.25GB, MaxMemAllocated=6.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:13:18,497] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:15:25,765] [INFO] [logging.py:75:log_dist] [Rank 0] step=4000, skipped=9, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:15:25,767] [INFO] [timer.py:198:stop] epoch=0/micro_step=4000/global_step=4000, RunningAvgSamplesPerSec=4.243191143499432, CurrSamplesPerSec=4.425734508941573, MemAllocated=2.25GB, MaxMemAllocated=6.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:17:08,754] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 512.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:21:58,625] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:23:47,318] [INFO] [logging.py:75:log_dist] [Rank 0] step=6000, skipped=11, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:23:47,319] [INFO] [timer.py:198:stop] epoch=0/micro_step=6000/global_step=6000, RunningAvgSamplesPerSec=4.280066930037287, CurrSamplesPerSec=4.473676126764169, MemAllocated=2.25GB, MaxMemAllocated=6.47GB\n",
      "[2024-04-23 12:24:48,248] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 512.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:32:08,711] [INFO] [logging.py:75:log_dist] [Rank 0] step=8000, skipped=12, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:32:08,712] [INFO] [timer.py:198:stop] epoch=0/micro_step=8000/global_step=8000, RunningAvgSamplesPerSec=4.29941305618266, CurrSamplesPerSec=4.581265141436583, MemAllocated=2.25GB, MaxMemAllocated=6.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:34:48,017] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048.0, reducing to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 12:39:57,789] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096.0, reducing to 4096.0\n",
      "[2024-04-23 12:40:11,007] [INFO] [stage_1_and_2.py:1769:step] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0\n",
      "[2024-04-23 12:40:23,544] [INFO] [logging.py:75:log_dist] [Rank 0] step=10000, skipped=15, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2024-04-23 12:40:23,545] [INFO] [timer.py:198:stop] epoch=0/micro_step=10000/global_step=10000, RunningAvgSamplesPerSec=4.313080317085133, CurrSamplesPerSec=4.4695095830678175, MemAllocated=2.25GB, MaxMemAllocated=6.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 118\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_residue(checkpoint, train, valid, batch=1, accum=1, epochs=10, seed=42, gpu=4, mixed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bab485",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8465267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Get accuracy value \n",
    "metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "\n",
    "epochs_loss = [x['epoch'] for x in history if 'loss' in x]\n",
    "epochs_eval = [x['epoch'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "# For the loss we plot a horizontal line because we have just one loss value (after the first epoch)\n",
    "# Exchange the two lines below if you trained multiple epochs\n",
    "#line1 = ax1.plot([0]+epochs_loss, loss*2, label='train_loss')\n",
    "line1 = ax1.plot(epochs_loss, loss, label='train_loss')\n",
    "\n",
    "line2 = ax1.plot(epochs_eval, val_loss, label='val_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "line3 = ax2.plot(epochs_eval, metric, color='red', label='val_accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 + line3\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4a53e",
   "metadata": {},
   "source": [
    "# Save and Load the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ade4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(checkpoint, filepath, mixed = True, full = False, deepspeed=True):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load model\n",
    "    if \"esm\" in checkpoint:\n",
    "        model, tokenizer = load_esm_model_regression(checkpoint, mixed, full, deepspeed)\n",
    "    else:\n",
    "        model, tokenizer = load_T5_model_regression(checkpoint, mixed, full, deepspeed)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ba621",
   "metadata": {},
   "source": [
    "This saves only the finetuned weights to a .pth file\n",
    "\n",
    "The file has a size of only a few MB, while the entire model would be around 4.8 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d31dc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,\"./scripts/Finetuning/PT5/ProtT5_disorder_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e96aa",
   "metadata": {},
   "source": [
    "To load the weights again, we initialize a new PT5 model from the pretrained checkpoint and load the LoRA weights afterwards\n",
    "\n",
    "You need to specifiy the correct num_labels here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edbd69f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/spiece.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Rostlab/prot_t5_xl_half_uniref50-enc\",\n",
      "  \"architectures\": [\n",
      "    \"T5EncoderModel\"\n",
      "  ],\n",
      "  \"d_ff\": 16384,\n",
      "  \"d_kv\": 128,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Rostlab/prot_t5_xl_half_uniref50-enc\",\n",
      "  \"architectures\": [\n",
      "    \"T5EncoderModel\"\n",
      "  ],\n",
      "  \"d_ff\": 16384,\n",
      "  \"d_kv\": 128,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /data2/cache/huggingface/hub/models--Rostlab--prot_t5_xl_half_uniref50-enc/snapshots/94a6abc029ae13029317b140b7424e012bf8dfbf/pytorch_model.bin\n",
      "Instantiating T5EncoderModel model under default dtype torch.float16.\n",
      "All model checkpoint weights were used when initializing T5EncoderModel.\n",
      "\n",
      "All the weights of T5EncoderModel were initialized from the model checkpoint at Rostlab/prot_t5_xl_half_uniref50-enc.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5EncoderModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5_Classfier\n",
      "Trainable Parameter: 1208142849\n",
      "T5_LoRA_Classfier\n",
      "Trainable Parameter: 1968129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model_reload = load_model(checkpoint, \"./scripts/Finetuning/PT5/ProtT5_disorder_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5289780",
   "metadata": {},
   "source": [
    "To check if the original and the reloaded models are identical we can compare weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e152714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c478158",
   "metadata": {},
   "source": [
    "# Make predictions on a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08533e20",
   "metadata": {},
   "source": [
    "We first load the SETH test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a9f505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18927</td>\n",
       "      <td>NREIQPPFKPKVSGKGAENFDKFFTRGQPVLTPPDQLVIANIDQSD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19650</td>\n",
       "      <td>LLDKDDSKAGMEEDHTYEGLDIDQTATYEDIVTLRTGEVKWSVGEHPGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15141</td>\n",
       "      <td>AKRSHQAIIMSTSLRVSPSIHGYHFDTASRKKAVGNIFENTDQESL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15768</td>\n",
       "      <td>STNPKPQRKTKRNTNRRPQDVKFPGGGQIVGGVYLLPRRGPRSQPR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17483</td>\n",
       "      <td>DAGRKGFGEKASEALKPDSQKSYAEQGKEYITDKADKVAGKVQPED...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                           sequence\n",
       "0  18927  NREIQPPFKPKVSGKGAENFDKFFTRGQPVLTPPDQLVIANIDQSD...\n",
       "1  19650  LLDKDDSKAGMEEDHTYEGLDIDQTATYEDIVTLRTGEVKWSVGEHPGQ\n",
       "2  15141  AKRSHQAIIMSTSLRVSPSIHGYHFDTASRKKAVGNIFENTDQESL...\n",
       "3  15768  STNPKPQRKTKRNTNRRPQDVKFPGGGQIVGGVYLLPRRGPRSQPR...\n",
       "4  17483  DAGRKGFGEKASEALKPDSQKSYAEQGKEYITDKADKVAGKVQPED..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test sequences\n",
    "url = \"https://raw.githubusercontent.com/DagmarIlz/SETH/main/datasets/CheZOD117_test_set_sequences.fasta\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Create a StringIO object to simulate a file-like object\n",
    "fasta_file = StringIO(response.text)\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "sequences = []\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    sequences.append([record.name, str(record.seq)])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f980510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18927</td>\n",
       "      <td>NREIQPPFKPKVSGKGAENFDKFFTRGQPVLTPPDQLVIANIDQSD...</td>\n",
       "      <td>[0.908, -0.087, 0.389, -1.393, -0.438, -2.381,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19650</td>\n",
       "      <td>LLDKDDSKAGMEEDHTYEGLDIDQTATYEDIVTLRTGEVKWSVGEHPGQ</td>\n",
       "      <td>[0.986, 1.055, -1.049, -0.312, 1.064, 2.683, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15141</td>\n",
       "      <td>AKRSHQAIIMSTSLRVSPSIHGYHFDTASRKKAVGNIFENTDQESL...</td>\n",
       "      <td>[-0.251, 0.539, 0.032, 0.33, -2.182, -1.09, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15768</td>\n",
       "      <td>STNPKPQRKTKRNTNRRPQDVKFPGGGQIVGGVYLLPRRGPRSQPR...</td>\n",
       "      <td>[7.239, 8.155, 6.443, 6.22, 4.927, 4.947, 2.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17483</td>\n",
       "      <td>DAGRKGFGEKASEALKPDSQKSYAEQGKEYITDKADKVAGKVQPED...</td>\n",
       "      <td>[-2.544, -2.447, -1.615, -1.252, -0.973, -2.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                           sequence  \\\n",
       "0  18927  NREIQPPFKPKVSGKGAENFDKFFTRGQPVLTPPDQLVIANIDQSD...   \n",
       "1  19650  LLDKDDSKAGMEEDHTYEGLDIDQTATYEDIVTLRTGEVKWSVGEHPGQ   \n",
       "2  15141  AKRSHQAIIMSTSLRVSPSIHGYHFDTASRKKAVGNIFENTDQESL...   \n",
       "3  15768  STNPKPQRKTKRNTNRRPQDVKFPGGGQIVGGVYLLPRRGPRSQPR...   \n",
       "4  17483  DAGRKGFGEKASEALKPDSQKSYAEQGKEYITDKADKVAGKVQPED...   \n",
       "\n",
       "                                               label  \n",
       "0  [0.908, -0.087, 0.389, -1.393, -0.438, -2.381,...  \n",
       "1  [0.986, 1.055, -1.049, -0.312, 1.064, 2.683, 2...  \n",
       "2  [-0.251, 0.539, 0.032, 0.33, -2.182, -1.09, 0....  \n",
       "3  [7.239, 8.155, 6.443, 6.22, 4.927, 4.947, 2.98...  \n",
       "4  [-2.544, -2.447, -1.615, -1.252, -0.973, -2.00...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test labels (CheZOD_scores) \n",
    "# here each test sequence label comes from it's own file\n",
    "\n",
    "labels=[] \n",
    "\n",
    "for n in list(df.name):\n",
    "    url = \"https://raw.githubusercontent.com/DagmarIlz/SETH/main/datasets/CheZOD117_test_set_CheZOD_scores/zscores\"+n+\".txt\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "    \n",
    "    lines = response.text.splitlines()\n",
    "    \n",
    "    label=[]\n",
    "    \n",
    "    for l in lines:\n",
    "        label.append(l.split(\" \")[-1]) \n",
    "    \n",
    "    labels.append(label)\n",
    "\n",
    "for l in range(0,len(labels)):\n",
    "    labels[l]=[float(label) for label in labels[l]]\n",
    "    \n",
    "df[\"label\"] = labels\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1151f4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_261625/2346974570.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['label'] = test.apply(lambda row:  [-100 if x > 900 else x for x in row['label']], axis=1)\n",
      "/tmp/ipykernel_261625/2346974570.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"sequence\"] = test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
      "/tmp/ipykernel_261625/2346974570.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['sequence'] = test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N R E I Q P P F K P K V S G K G A E N F D K F ...</td>\n",
       "      <td>[0.908, -0.087, 0.389, -1.393, -0.438, -2.381,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L L D K D D S K A G M E E D H T Y E G L D I D ...</td>\n",
       "      <td>[0.986, 1.055, -1.049, -0.312, 1.064, 2.683, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A K R S H Q A I I M S T S L R V S P S I H G Y ...</td>\n",
       "      <td>[-0.251, 0.539, 0.032, 0.33, -2.182, -1.09, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S T N P K P Q R K T K R N T N R R P Q D V K F ...</td>\n",
       "      <td>[7.239, 8.155, 6.443, 6.22, 4.927, 4.947, 2.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D A G R K G F G E K A S E A L K P D S Q K S Y ...</td>\n",
       "      <td>[-2.544, -2.447, -1.615, -1.252, -0.973, -2.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  N R E I Q P P F K P K V S G K G A E N F D K F ...   \n",
       "1  L L D K D D S K A G M E E D H T Y E G L D I D ...   \n",
       "2  A K R S H Q A I I M S T S L R V S P S I H G Y ...   \n",
       "3  S T N P K P Q R K T K R N T N R R P Q D V K F ...   \n",
       "4  D A G R K G F G E K A S E A L K P D S Q K S Y ...   \n",
       "\n",
       "                                               label  \n",
       "0  [0.908, -0.087, 0.389, -1.393, -0.438, -2.381,...  \n",
       "1  [0.986, 1.055, -1.049, -0.312, 1.064, 2.683, 2...  \n",
       "2  [-0.251, 0.539, 0.032, 0.33, -2.182, -1.09, 0....  \n",
       "3  [7.239, 8.155, 6.443, 6.22, 4.927, 4.947, 2.98...  \n",
       "4  [-2.544, -2.447, -1.615, -1.252, -0.973, -2.00...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[[\"sequence\", \"label\"]]\n",
    "\n",
    "# replace invalid values above 900 with -100\n",
    "test['label'] = test.apply(lambda row:  [-100 if x > 900 else x for x in row['label']], axis=1)\n",
    "\n",
    "# preprocess data\n",
    "test[\"sequence\"] = test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"J\"]),\"X\",regex=True)\n",
    "test['sequence'] = test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249f897",
   "metadata": {},
   "source": [
    "Then we create predictions on our test data using the model we trained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1df2299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8/8 [00:11<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Create Dataset\n",
    "test_set=create_dataset(tokenizer,list(test['sequence']),list(test['label']),checkpoint)\n",
    "# Make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# For token regression we need a data collator here to pad correctly\n",
    "if (\"esm\" in checkpoint) or (\"ProstT5\" in checkpoint):\n",
    "    data_collator = DataCollatorForTokenRegression_esm(tokenizer) \n",
    "# For Ankh and ProtT5 pad only at the end\n",
    "else:\n",
    "    data_collator = DataCollatorForTokenRegression_t5(tokenizer)    \n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle = False, collate_fn = data_collator)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = []\n",
    "# We need to collect the batch[\"labels\"] as well, this allows us to filter out all positions with a -100 afterwards\n",
    "padded_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # Padded labels from the data collator\n",
    "        padded_labels += batch['labels'].tolist()\n",
    "        # Add batch results(logits) to predictions, we take the argmax here to get the predicted class\n",
    "        predictions += model.float()(input_ids, attention_mask=attention_mask).logits.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18401de",
   "metadata": {},
   "source": [
    "Finally, we compute our desired performance metric for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "000028da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  0.7221329212807391\n"
     ]
    }
   ],
   "source": [
    "# to make it easier we flatten both the label and prediction lists\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "# flatten and convert to np array for easy slicing in the next step\n",
    "predictions = np.array(flatten(predictions))\n",
    "padded_labels = np.array(flatten(padded_labels))\n",
    "\n",
    "# Filter out all invalid (label = -100) values\n",
    "predictions = predictions[padded_labels!=-100]\n",
    "padded_labels = padded_labels[padded_labels!=-100]\n",
    "\n",
    "# Calculate classification Accuracy\n",
    "print(\"Spearman: \", stats.spearmanr(a=predictions, b=padded_labels, axis=0).correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee716709",
   "metadata": {},
   "source": [
    "Great, 72.2% Spearman is a decent test performance for this test dataset (see [SETH](https://www.frontiersin.org/articles/10.3389/fbinf.2022.1019597/full) results )\n",
    "\n",
    "Further hyperparameter optimization and using a CNN prediction head will further increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c2e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb",
     "timestamp": 1670229986129
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
